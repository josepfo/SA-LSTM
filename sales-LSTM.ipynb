{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math, time\n",
    "import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# fixar random seed para se puder reproduzir os resultados\n",
    "seed = 9\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_dataset(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    print('Formato do dataset: ',df.shape)\n",
    "    print('Feature Engineering...')\n",
    "    date_split = df['Month'].str.split('-').str\n",
    "    df['Year'], df['Month'] = date_split\n",
    "    m = {'Jan':1, 'Feb':2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7, 'Aug':8, 'Sep':9, 'Oct':10, 'Nov':11, 'Dec':12, }\n",
    "    df['Month'] = df['Month'].map(m)\n",
    "    df.drop(df.columns[[3,4,5,6]], axis=1, inplace=True) #vou só ficar com as colunas 0,1,2,6\n",
    "    df.drop(df.tail(2).index,inplace=True) #eliminar as duas últimas linhas com lixo\n",
    "    df.dropna() #just to be sure\n",
    "    df = df.astype(dtype=np.float64)\n",
    "    #df[\"Year\"] = df[\"Year\"].astype(dtype=np.float64) #converter coluna do ano para floats\n",
    "    print('Formato do dataset: ',df.shape)\n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função load_data do lstm.py configurada para aceitar qualquer número de parametros\n",
    "#o último atributo é que fica como label (resultado)\n",
    "#stock é um dataframe do pandas (uma especie de dicionario + matriz)\n",
    "#seq_len é o tamanho da janela a ser utilizada na serie temporal\n",
    "def load_data(df_dados, janela):\n",
    "    qt_atributos = len(df_dados.columns)\n",
    "    tam_sequencia = janela + 1\n",
    "    #converter dataframe para matriz (lista com lista de cada registo)\n",
    "    #fazendo a divisão já em dados de teste e treino\n",
    "    train_matrix =  df_dados.iloc[:24].values\n",
    "    test_matrix = df_dados.iloc[24:].values\n",
    "    #processamento dados de treino de acordo com o tamanho da janela\n",
    "    train = []\n",
    "    for i in range(len(train_matrix) - tam_sequencia): #numero de registos - tamanho da sequencia\n",
    "        train.append(train_matrix[i: i + tam_sequencia])\n",
    "    #dá como resultado um np com uma lista de matrizes (janela deslizante ao longo da serie)\n",
    "    train = np.array(train)\n",
    "    #processamento dados de test de acordo com o tamanho da janela\n",
    "    test = []\n",
    "    for i in range(len(test_matrix) - tam_sequencia): #numero de registos - tamanho da sequencia\n",
    "        test.append(test_matrix[i: i + tam_sequencia])\n",
    "    #dá como resultado um np com uma lista de matrizes (janela deslizante ao longo da serie)\n",
    "    test = np.array(test)\n",
    "    x_train = train[:, :-1] #menos um registo pois o ultimo registo é o registo a seguir à janela\n",
    "    y_train = train[:, -1][:,2] #para ir buscar o atributo referente às sales para a lista dos labels\n",
    "    x_test = test[:, :-1]\n",
    "    y_test = test[:, -1][:,2]\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], qt_atributos))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], qt_atributos))\n",
    "    return [x_train,y_train,x_test,y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 2 - Definir a topologia da rede (arquitectura do modelo) e compilar '''\n",
    "def build_model_tarraxo(janela):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(janela, 4), return_sequences=True))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(LSTM(64, input_shape=(janela, 4), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32, input_shape=(janela, 4), return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(1, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 2 - Definir a topologia da rede (arquitectura do modelo) e compilar '''\n",
    "def build_model_campos(janela):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(janela, 4), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, input_shape=(janela, 4), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64, input_shape=(janela, 4), return_sequences=False))\n",
    "    model.add(Dense(16, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(1, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(model,fich):\n",
    " from keras.utils import plot_model\n",
    " plot_model(model, to_file=fich, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprime um grafico com os valores de teste e com as correspondentes tabela de previsões\n",
    "def print_series_prediction(y_test,predic):\n",
    "    diff=[]\n",
    "    racio=[]\n",
    "    for i in range(len(y_test)): #para imprimir tabela de previsoes\n",
    "        racio.append( (y_test[i]/predic[i])-1)\n",
    "        diff.append( abs(y_test[i]- predic[i]))\n",
    "        print('valor: %f ---> Previsão: %f Diff: %f Racio: %f' % (y_test[i],predic[i], diff[i],racio[i]))\n",
    "    plt.plot(y_test,color='blue', label='y_test')\n",
    "    plt.plot(predic,color='red', label='prediction') #este deu uma linha em branco\n",
    "    plt.plot(diff,color='green', label='diff')\n",
    "    plt.plot(racio,color='yellow', label='racio')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization (df):\n",
    "    print('Normalization...')\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    scaled_features = min_max_scaler.fit_transform(df)\n",
    "    df = pd.DataFrame(scaled_features,columns=df.columns)\n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing (df):\n",
    "    print('Preprocessssing...')\n",
    "    df['Month'] = df['Month'] / 100\n",
    "    df['Advertising'] = df['Advertising'] / 100\n",
    "    df['Sales'] = df['Sales'] / 100\n",
    "    df['Year'] = df['Year'] / 100\n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "MSE- (Mean square error), RMSE- (root mean square error) –\n",
    "o significado de RMSE depende do range da label. para o mesmo range menor é melhor.\n",
    "'''\n",
    "def sales_LSTM():\n",
    "    df = read_csv_dataset(\"advertising-and-sales-data-36-co.csv\")\n",
    "    df = pre_processing(df)\n",
    "    print(\"df\", df.shape)\n",
    "    janela = 2 #tamanho da Janela deslizante\n",
    "    X_train, y_train, X_test, y_test = load_data(df, janela)\n",
    "    print(\"X_train\", X_train.shape)\n",
    "    print(\"y_train\", y_train.shape)\n",
    "    print(\"X_test\", X_test.shape)\n",
    "    print(\"y_test\", y_test.shape)\n",
    "    model = build_model_tarraxo(janela)\n",
    "    model.fit(X_train, y_train, batch_size=4, epochs=200, validation_split=0.1, verbose=1)\n",
    "    print_model(model,\"lstm_model.png\")\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    print(model.metrics_names)\n",
    "    p = model.predict(X_test)\n",
    "    #para transformar uma matriz de uma coluna e n linhas em um np array de n elementos\n",
    "    predic = np.squeeze(np.asarray(p))\n",
    "    print_series_prediction(y_test,predic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato do dataset:  (38, 7)\n",
      "Feature Engineering...\n",
      "Formato do dataset:  (36, 4)\n",
      "   Month  Advertising  Sales  Year\n",
      "0    1.0         12.0   15.0   1.0\n",
      "1    2.0         20.5   16.0   1.0\n",
      "2    3.0         21.0   18.0   1.0\n",
      "3    4.0         15.5   27.0   1.0\n",
      "4    5.0         15.3   21.0   1.0\n",
      "Preprocessssing...\n",
      "   Month  Advertising  Sales  Year\n",
      "0   0.01        0.120   0.15  0.01\n",
      "1   0.02        0.205   0.16  0.01\n",
      "2   0.03        0.210   0.18  0.01\n",
      "3   0.04        0.155   0.27  0.01\n",
      "4   0.05        0.153   0.21  0.01\n",
      "df (36, 4)\n",
      "X_train (21, 2, 4)\n",
      "y_train (21,)\n",
      "X_test (9, 2, 4)\n",
      "y_test (9,)\n",
      "Train on 18 samples, validate on 3 samples\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.1477 - acc: 0.0000e+00 - val_loss: 0.0379 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1433 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1387 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.1340 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.1278 - acc: 0.0000e+00 - val_loss: 0.0264 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.1206 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.1103 - acc: 0.0000e+00 - val_loss: 0.0167 - val_acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0954 - acc: 0.0000e+00 - val_loss: 0.0103 - val_acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0769 - acc: 0.0000e+00 - val_loss: 0.0043 - val_acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0503 - acc: 0.0000e+00 - val_loss: 0.0070 - val_acc: 0.0000e+00\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0631 - val_acc: 0.0000e+00\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0371 - acc: 0.0000e+00 - val_loss: 0.0518 - val_acc: 0.0000e+00\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0268 - val_acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0307 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0320 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0000e+00\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0301 - val_acc: 0.0000e+00\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0295 - val_acc: 0.0000e+00\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0339 - acc: 0.0000e+00 - val_loss: 0.0319 - val_acc: 0.0000e+00\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0317 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0316 - val_acc: 0.0000e+00\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0309 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0378 - val_acc: 0.0000e+00\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0431 - val_acc: 0.0000e+00\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0414 - val_acc: 0.0000e+00\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0220 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0323 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0247 - val_acc: 0.0000e+00\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0293 - val_acc: 0.0000e+00\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0246 - acc: 0.0000e+00 - val_loss: 0.0366 - val_acc: 0.0000e+00\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.0000e+00\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0290 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0371 - val_acc: 0.0000e+00\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0449 - val_acc: 0.0000e+00\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0448 - val_acc: 0.0000e+00\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0246 - acc: 0.0000e+00 - val_loss: 0.0396 - val_acc: 0.0000e+00\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0295 - val_acc: 0.0000e+00\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0311 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0307 - val_acc: 0.0000e+00\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0297 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0000e+00\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0385 - val_acc: 0.0000e+00\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0374 - val_acc: 0.0000e+00\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0404 - val_acc: 0.0000e+00\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0301 - acc: 0.0000e+00 - val_loss: 0.0417 - val_acc: 0.0000e+00\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.0000e+00\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0233 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0301 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0239 - acc: 0.0000e+00 - val_loss: 0.0411 - val_acc: 0.0000e+00\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.0420 - val_acc: 0.0000e+00\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0292 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0308 - val_acc: 0.0000e+00\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0405 - val_acc: 0.0000e+00\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0419 - val_acc: 0.0000e+00\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.0366 - val_acc: 0.0000e+00\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0379 - val_acc: 0.0000e+00\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0386 - val_acc: 0.0000e+00\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0422 - val_acc: 0.0000e+00\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0369 - val_acc: 0.0000e+00\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0371 - val_acc: 0.0000e+00\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0411 - val_acc: 0.0000e+00\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0204 - acc: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.0000e+00\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0257 - val_acc: 0.0000e+00\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0301 - val_acc: 0.0000e+00\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0220 - acc: 0.0000e+00 - val_loss: 0.0421 - val_acc: 0.0000e+00\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0290 - acc: 0.0000e+00 - val_loss: 0.0472 - val_acc: 0.0000e+00\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0287 - acc: 0.0000e+00 - val_loss: 0.0429 - val_acc: 0.0000e+00\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 112/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0319 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0217 - acc: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.0000e+00\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0242 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0379 - val_acc: 0.0000e+00\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0229 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0223 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0239 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0217 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0384 - val_acc: 0.0000e+00\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.0301 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0240 - acc: 0.0000e+00 - val_loss: 0.0394 - val_acc: 0.0000e+00\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0250 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0399 - val_acc: 0.0000e+00\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0216 - acc: 0.0000e+00 - val_loss: 0.0364 - val_acc: 0.0000e+00\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0223 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0209 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0223 - acc: 0.0000e+00 - val_loss: 0.0367 - val_acc: 0.0000e+00\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0267 - val_acc: 0.0000e+00\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0226 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0362 - val_acc: 0.0000e+00\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.0000e+00\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0246 - acc: 0.0000e+00 - val_loss: 0.0411 - val_acc: 0.0000e+00\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0222 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0271 - val_acc: 0.0000e+00\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0210 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0212 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0246 - acc: 0.0000e+00 - val_loss: 0.0379 - val_acc: 0.0000e+00\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0208 - acc: 0.0000e+00 - val_loss: 0.0379 - val_acc: 0.0000e+00\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 0.0242 - acc: 0.0000e+00 - val_loss: 0.0301 - val_acc: 0.0000e+00\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0227 - acc: 0.0000e+00 - val_loss: 0.0287 - val_acc: 0.0000e+00\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0224 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 170/200\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0249 - val_acc: 0.0000e+00\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0247 - val_acc: 0.0000e+00\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0213 - acc: 0.0000e+00 - val_loss: 0.0436 - val_acc: 0.0000e+00\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0000e+00\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0302 - val_acc: 0.0000e+00\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0226 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0264 - val_acc: 0.0000e+00\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0000e+00\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0194 - acc: 0.0000e+00 - val_loss: 0.0375 - val_acc: 0.0000e+00\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0000e+00\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0193 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0371 - val_acc: 0.0000e+00\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0327 - val_acc: 0.0000e+00\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0201 - acc: 0.0000e+00 - val_loss: 0.0286 - val_acc: 0.0000e+00\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0197 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0226 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.0208 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0200 - acc: 0.0000e+00 - val_loss: 0.0319 - val_acc: 0.0000e+00\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 0.0221 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0308 - val_acc: 0.0000e+00\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 0.0183 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.0242 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Train Score: 0.02 MSE (0.15 RMSE)\n",
      "Test Score: 0.05 MSE (0.23 RMSE)\n",
      "['loss', 'acc']\n",
      "valor: 0.360000 ---> Previsão: 0.353315 Diff: 0.006685 Racio: 0.018921\n",
      "valor: 0.400000 ---> Previsão: 0.383604 Diff: 0.016396 Racio: 0.042742\n",
      "valor: 0.490000 ---> Previsão: 0.430735 Diff: 0.059265 Racio: 0.137590\n",
      "valor: 0.070000 ---> Previsão: 0.438480 Diff: 0.368480 Racio: -0.840357\n",
      "valor: 0.520000 ---> Previsão: 0.415297 Diff: 0.104703 Racio: 0.252115\n",
      "valor: 0.650000 ---> Previsão: 0.338985 Diff: 0.311015 Racio: 0.917488\n",
      "valor: 0.170000 ---> Previsão: 0.437066 Diff: 0.267066 Racio: -0.611043\n",
      "valor: 0.050000 ---> Previsão: 0.420826 Diff: 0.370826 Racio: -0.881186\n",
      "valor: 0.170000 ---> Previsão: 0.293060 Diff: 0.123060 Racio: -0.419914\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    sales_LSTM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
