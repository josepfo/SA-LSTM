{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math, time\n",
    "import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# fixar random seed para se puder reproduzir os resultados\n",
    "seed = 9\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_dataset(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    print('Formato do dataset: ',df.shape)\n",
    "    print('Feature Engineering...')\n",
    "    date_split = df['Month'].str.split('-').str\n",
    "    df['Year'], df['Month'] = date_split\n",
    "    m = {'Jan':1, 'Feb':2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7, 'Aug':8, 'Sep':9, 'Oct':10, 'Nov':11, 'Dec':12, }\n",
    "    df['Month'] = df['Month'].map(m)\n",
    "    df.drop(df.columns[[3,4,5,6]], axis=1, inplace=True) #vou só ficar com as colunas 0,1,2,6\n",
    "    df.drop(df.tail(2).index,inplace=True) #eliminar as duas últimas linhas com lixo\n",
    "    df.dropna() #just to be sure\n",
    "    df[\"Year\"] = df[\"Year\"].astype(dtype=np.float64) #converter coluna do ano para floats\n",
    "    print('Formato do dataset: ',df.shape)\n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função load_data do lstm.py configurada para aceitar qualquer número de parametros\n",
    "#o último atributo é que fica como label (resultado)\n",
    "#stock é um dataframe do pandas (uma especie de dicionario + matriz)\n",
    "#seq_len é o tamanho da janela a ser utilizada na serie temporal\n",
    "def load_data(df_dados, janela):\n",
    "    #print(df_dados)\n",
    "    qt_atributos = len(df_dados.columns)\n",
    "    tam_sequencia = janela + 1\n",
    "    #converter dataframe para matriz (lista com lista de cada registo) fazendo a divisão já em dados de teste e treino\n",
    "    train_matrix =  df_dados.iloc[:24].as_matrix()\n",
    "    test_matrix = df_dados.iloc[24:].as_matrix()\n",
    "    \n",
    "    #processamento dados de treino de acordo com o tamanho da janela\n",
    "    train = []\n",
    "    for i in range(len(train_matrix) - tam_sequencia): #numero de registos - tamanho da sequencia\n",
    "        train.append(train_matrix[i: i + tam_sequencia])\n",
    "    train = np.array(train) #dá como resultado um np com uma lista de matrizes (janela deslizante ao longo da serie)\n",
    "    #print(train.shape)\n",
    "    \n",
    "    #processamento dados de test de acordo com o tamanho da janela\n",
    "    test = []\n",
    "    for i in range(len(test_matrix) - tam_sequencia):\n",
    "        test.append(test_matrix[i: i + tam_sequencia])\n",
    "    test = np.array(test)\n",
    "    #print(test.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x_train = train[:, :-1] #menos um registo pois o ultimo registo é o registo a seguir à janela\n",
    "    y_train = train[:, -1][:,2] #para ir buscar o atributo referente às sales para a lista dos labels\n",
    "    x_test = test[:, :-1]\n",
    "    y_test = test[:, -1][:,2]\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], qt_atributos))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], qt_atributos))\n",
    "   # print(\"TRAIN\",train)\n",
    "   # print(\"TEST\",test)\n",
    "   # print(\"X_TRAIN\",x_train)\n",
    "   # print(\"Y_TRAIN\",y_train)\n",
    "   # print(\"X_TEST\",x_test)\n",
    "   # print(\"Y_TEST\",y_test)\n",
    "    return [x_train,y_train,x_test,y_test]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 2 - Definir a topologia da rede (arquitectura do modelo) e compilar '''\n",
    "def build_model2(janela):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(janela, 4), return_sequences=True))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(LSTM(64, input_shape=(janela, 4), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32, input_shape=(janela, 4), return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(1, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(model,fich):\n",
    " from keras.utils import plot_model\n",
    " plot_model(model, to_file=fich, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprime um grafico com os valores de teste e com as correspondentes tabela de previsões\n",
    "def print_series_prediction(y_test,predic):\n",
    "    diff=[]\n",
    "    racio=[]\n",
    "    for i in range(len(y_test)): #para imprimir tabela de previsoes\n",
    "        racio.append( (y_test[i]/predic[i])-1)\n",
    "        diff.append( abs(y_test[i]- predic[i]))\n",
    "        print('valor: %f ---> Previsão: %f Diff: %f Racio: %f' % (y_test[i],predic[i], diff[i],racio[i]))\n",
    "    plt.plot(y_test,color='blue', label='y_test')\n",
    "    plt.plot(predic,color='red', label='prediction') #este deu uma linha em branco\n",
    "    plt.plot(diff,color='green', label='diff')\n",
    "    plt.plot(racio,color='yellow', label='racio')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization (df):\n",
    "    \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    scaled_features = min_max_scaler.fit_transform(df)\n",
    "    df = pd.DataFrame(scaled_features,columns=df.columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing (df):\n",
    "    \n",
    "    df['Month'] = df['Month'] / 100\n",
    "    df['Advertising'] = df['Advertising'] / 100\n",
    "    df['Sales'] = df['Sales'] / 100\n",
    "    df['Year'] = df['Year'] / 100\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_():\n",
    "    df = read_csv_dataset(\"advertising-and-sales-data-36-co.csv\")\n",
    "    df = pre_processing(df)\n",
    "    print(\"df\", df.shape)\n",
    "    print(df.head())\n",
    "    janela = 2 #tamanho da Janela deslizante\n",
    "    #X_train, y_train, X_test, y_test = load_data(df[::-1], janela)# o df[::-1] é o df por ordem inversa\n",
    "    X_train, y_train, X_test, y_test = load_data(df, janela)# o ler o def por ordem normal\n",
    "    print(\"X_train\", X_train.shape)\n",
    "    print(\"y_train\", y_train.shape)\n",
    "    print(\"X_test\", X_test.shape)\n",
    "    print(\"y_test\", y_test.shape)\n",
    "    model = build_model2(janela)\n",
    "    model.fit(X_train, y_train, batch_size=512, epochs=200, validation_split=0.1, verbose=1)\n",
    "    #print_model(model,\"lstm_model.png\")\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    print(model.metrics_names)\n",
    "    p = model.predict(X_test)\n",
    "    predic = np.squeeze(np.asarray(p)) #para transformar uma matriz de uma coluna e n linhas em um np array de n elementos\n",
    "    print_series_prediction(y_test,predic)\n",
    "    # MSE- (Mean square error), RMSE- (root mean square error) - \n",
    "    # o significado de RMSE depende do range da label. para o mesmo range menor é melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato do dataset:  (38, 7)\n",
      "Feature Engineering...\n",
      "Formato do dataset:  (36, 4)\n",
      "   Month  Advertising  Sales  Year\n",
      "0    1.0         12.0   15.0   1.0\n",
      "1    2.0         20.5   16.0   1.0\n",
      "2    3.0         21.0   18.0   1.0\n",
      "3    4.0         15.5   27.0   1.0\n",
      "4    5.0         15.3   21.0   1.0\n",
      "df (36, 4)\n",
      "   Month  Advertising  Sales  Year\n",
      "0   0.01        0.120   0.15  0.01\n",
      "1   0.02        0.205   0.16  0.01\n",
      "2   0.03        0.210   0.18  0.01\n",
      "3   0.04        0.155   0.27  0.01\n",
      "4   0.05        0.153   0.21  0.01\n",
      "X_train (21, 2, 4)\n",
      "y_train (21,)\n",
      "X_test (9, 2, 4)\n",
      "y_test (9,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18 samples, validate on 3 samples\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 34s 2s/step - loss: 0.1492 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1483 - acc: 0.0000e+00 - val_loss: 0.0392 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1475 - acc: 0.0000e+00 - val_loss: 0.0388 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1467 - acc: 0.0000e+00 - val_loss: 0.0383 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1458 - acc: 0.0000e+00 - val_loss: 0.0378 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1449 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1440 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1431 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1422 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1412 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1403 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1393 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1383 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1372 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1362 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1351 - acc: 0.0000e+00 - val_loss: 0.0319 - val_acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1340 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1327 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1315 - acc: 0.0000e+00 - val_loss: 0.0299 - val_acc: 0.0000e+00\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1301 - acc: 0.0000e+00 - val_loss: 0.0292 - val_acc: 0.0000e+00\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1289 - acc: 0.0000e+00 - val_loss: 0.0285 - val_acc: 0.0000e+00\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1275 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0000e+00\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1258 - acc: 0.0000e+00 - val_loss: 0.0269 - val_acc: 0.0000e+00\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1241 - acc: 0.0000e+00 - val_loss: 0.0260 - val_acc: 0.0000e+00\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1226 - acc: 0.0000e+00 - val_loss: 0.0251 - val_acc: 0.0000e+00\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1209 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0000e+00\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1186 - acc: 0.0000e+00 - val_loss: 0.0232 - val_acc: 0.0000e+00\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1162 - acc: 0.0000e+00 - val_loss: 0.0221 - val_acc: 0.0000e+00\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1141 - acc: 0.0000e+00 - val_loss: 0.0210 - val_acc: 0.0000e+00\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1123 - acc: 0.0000e+00 - val_loss: 0.0197 - val_acc: 0.0000e+00\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1092 - acc: 0.0000e+00 - val_loss: 0.0184 - val_acc: 0.0000e+00\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1070 - acc: 0.0000e+00 - val_loss: 0.0171 - val_acc: 0.0000e+00\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1035 - acc: 0.0000e+00 - val_loss: 0.0156 - val_acc: 0.0000e+00\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0996 - acc: 0.0000e+00 - val_loss: 0.0141 - val_acc: 0.0000e+00\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0969 - acc: 0.0000e+00 - val_loss: 0.0125 - val_acc: 0.0000e+00\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0941 - acc: 0.0000e+00 - val_loss: 0.0109 - val_acc: 0.0000e+00\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0874 - acc: 0.0000e+00 - val_loss: 0.0093 - val_acc: 0.0000e+00\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0845 - acc: 0.0000e+00 - val_loss: 0.0077 - val_acc: 0.0000e+00\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0808 - acc: 0.0000e+00 - val_loss: 0.0063 - val_acc: 0.0000e+00\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0724 - acc: 0.0000e+00 - val_loss: 0.0050 - val_acc: 0.0000e+00\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0695 - acc: 0.0000e+00 - val_loss: 0.0041 - val_acc: 0.0000e+00\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0618 - acc: 0.0000e+00 - val_loss: 0.0036 - val_acc: 0.0000e+00\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0574 - acc: 0.0000e+00 - val_loss: 0.0040 - val_acc: 0.0000e+00\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0493 - acc: 0.0000e+00 - val_loss: 0.0053 - val_acc: 0.0000e+00\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0445 - acc: 0.0000e+00 - val_loss: 0.0080 - val_acc: 0.0000e+00\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0428 - acc: 0.0000e+00 - val_loss: 0.0124 - val_acc: 0.0000e+00\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0188 - val_acc: 0.0000e+00\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0388 - val_acc: 0.0000e+00\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0246 - acc: 0.0000e+00 - val_loss: 0.0518 - val_acc: 0.0000e+00\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0313 - acc: 0.0000e+00 - val_loss: 0.0639 - val_acc: 0.0000e+00\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0314 - acc: 0.0000e+00 - val_loss: 0.0735 - val_acc: 0.0000e+00\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0794 - val_acc: 0.0000e+00\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0388 - acc: 0.0000e+00 - val_loss: 0.0800 - val_acc: 0.0000e+00\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0401 - acc: 0.0000e+00 - val_loss: 0.0769 - val_acc: 0.0000e+00\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0342 - acc: 0.0000e+00 - val_loss: 0.0711 - val_acc: 0.0000e+00\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0643 - val_acc: 0.0000e+00\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0573 - val_acc: 0.0000e+00\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0506 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0445 - val_acc: 0.0000e+00\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0392 - val_acc: 0.0000e+00\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0272 - val_acc: 0.0000e+00\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0231 - val_acc: 0.0000e+00\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0000e+00\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0246 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0000e+00\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0335 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0000e+00\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0318 - acc: 0.0000e+00 - val_loss: 0.0206 - val_acc: 0.0000e+00\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0208 - val_acc: 0.0000e+00\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0212 - val_acc: 0.0000e+00\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0242 - acc: 0.0000e+00 - val_loss: 0.0219 - val_acc: 0.0000e+00\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0229 - val_acc: 0.0000e+00\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0241 - val_acc: 0.0000e+00\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0255 - val_acc: 0.0000e+00\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0272 - val_acc: 0.0000e+00\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0288 - val_acc: 0.0000e+00\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0377 - val_acc: 0.0000e+00\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0388 - val_acc: 0.0000e+00\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0401 - val_acc: 0.0000e+00\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0402 - val_acc: 0.0000e+00\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0401 - val_acc: 0.0000e+00\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0304 - acc: 0.0000e+00 - val_loss: 0.0400 - val_acc: 0.0000e+00\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0392 - val_acc: 0.0000e+00\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0385 - val_acc: 0.0000e+00\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0376 - val_acc: 0.0000e+00\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0267 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0233 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0295 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0000e+00\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0244 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0331 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0220 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0229 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0218 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0240 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0300 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0228 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0239 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0283 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0276 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0305 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0000e+00\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0297 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0000e+00\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0280 - acc: 0.0000e+00 - val_loss: 0.0327 - val_acc: 0.0000e+00\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0224 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0208 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0334 - val_acc: 0.0000e+00\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0292 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0318 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0302 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0221 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0269 - acc: 0.0000e+00 - val_loss: 0.0355 - val_acc: 0.0000e+00\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0234 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0310 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0292 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0292 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0265 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0303 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0220 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0224 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0216 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0344 - val_acc: 0.0000e+00\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0300 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0226 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Train Score: 0.03 MSE (0.16 RMSE)\n",
      "Test Score: 0.05 MSE (0.22 RMSE)\n",
      "['loss', 'acc']\n",
      "valor: 0.360000 ---> Previsão: 0.310836 Diff: 0.049164 Racio: 0.158167\n",
      "valor: 0.400000 ---> Previsão: 0.338965 Diff: 0.061035 Racio: 0.180061\n",
      "valor: 0.490000 ---> Previsão: 0.376658 Diff: 0.113342 Racio: 0.300916\n",
      "valor: 0.070000 ---> Previsão: 0.388133 Diff: 0.318133 Racio: -0.819649\n",
      "valor: 0.520000 ---> Previsão: 0.384948 Diff: 0.135052 Racio: 0.350831\n",
      "valor: 0.650000 ---> Previsão: 0.340065 Diff: 0.309935 Racio: 0.911401\n",
      "valor: 0.170000 ---> Previsão: 0.403389 Diff: 0.233389 Racio: -0.578571\n",
      "valor: 0.050000 ---> Previsão: 0.405575 Diff: 0.355575 Racio: -0.876718\n",
      "valor: 0.170000 ---> Previsão: 0.334014 Diff: 0.164014 Racio: -0.491040\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    " #visualize_GOOGL()\n",
    " LSTM_()\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
