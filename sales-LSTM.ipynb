{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math, time\n",
    "import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "# fixar random seed para se puder reproduzir os resultados\n",
    "seed = 9\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_dataset(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    print('Formato do dataset: ',df.shape)\n",
    "    print('Feature Engineering...')\n",
    "    date_split = df['Month'].str.split('-').str\n",
    "    df['Year'], df['Month'] = date_split\n",
    "    m = {'Jan':1, 'Feb':2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7, 'Aug':8, 'Sep':9, 'Oct':10, 'Nov':11, 'Dec':12, }\n",
    "    df['Month'] = df['Month'].map(m)\n",
    "    df.drop(df.columns[[3,4,5,6]], axis=1, inplace=True) #vou só ficar com as colunas 0,1,2,6\n",
    "    df.drop(df.tail(2).index,inplace=True) #eliminar as duas últimas linhas com lixo\n",
    "    df.dropna() #just to be sure\n",
    "    df[\"Year\"] = df[\"Year\"].astype(dtype=np.float64) #converter coluna do ano para floats\n",
    "    print('Formato do dataset: ',df.shape)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função load_data do lstm.py configurada para aceitar qualquer número de parametros\n",
    "#o último atributo é que fica como label (resultado)\n",
    "#stock é um dataframe do pandas (uma especie de dicionario + matriz)\n",
    "#seq_len é o tamanho da janela a ser utilizada na serie temporal\n",
    "def load_data(df_dados, janela):\n",
    "    #print(df_dados)\n",
    "    qt_atributos = len(df_dados.columns)\n",
    "    mat_dados = df_dados.as_matrix() #converter dataframe para matriz (lista com lista de cada registo)\n",
    "    tam_sequencia = janela + 1\n",
    "    res = []\n",
    "    for i in range(len(mat_dados) - tam_sequencia): #numero de registos - tamanho da sequencia\n",
    "         res.append(mat_dados[i: i + tam_sequencia])\n",
    "    res = np.array(res) #dá como resultado um np com uma lista de matrizes (janela deslizante ao longo da serie)\n",
    "    print(res.shape)\n",
    "\n",
    "    #escolher apenas os dados referentes ao primeiro e segundo ano para treinar a rede e do terceiro para testar\n",
    "\n",
    "    qt_casos_treino = 0\n",
    "    for i in range(len(res)):\n",
    "        fortrain = 0\n",
    "        for j in range(len(res[i])):\n",
    "            if (res[i][j][3] < 3):\n",
    "                fortrain = 1\n",
    "        qt_casos_treino += fortrain \n",
    "    \n",
    "    #qt_casos_treino = int(round(0.9 * res.shape[0])) #90% passam a ser casos de treino\n",
    "    \n",
    "    train = res[:qt_casos_treino, :]\n",
    "    x_train = train[:, :-1] #menos um registo pois o ultimo registo é o registo a seguir à janela\n",
    "    y_train = train[:, -1][:,2] #para ir buscar o atributo referente às sales para a lista dos labels\n",
    "    x_test = res[qt_casos_treino:, :-1]\n",
    "    y_test = res[qt_casos_treino:, -1][:,2]\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], qt_atributos))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], qt_atributos))\n",
    "   # print(\"TRAIN\",train)\n",
    "   # print(\"X_TRAIN\",x_train)\n",
    "   # print(\"Y_TRAIN\",y_train)\n",
    "   # print(\"X_TEST\",x_test)\n",
    "   # print(\"Y_TEST\",y_test)\n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 2 - Definir a topologia da rede (arquitectura do modelo) e compilar '''\n",
    "def build_model2(janela):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(256, input_shape=(janela, 4), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, input_shape=(janela, 4), return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64, input_shape=(janela, 4), return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(1, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(model,fich):\n",
    " from keras.utils import plot_model\n",
    " plot_model(model, to_file=fich, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprime um grafico com os valores de teste e com as correspondentes tabela de previsões\n",
    "def print_series_prediction(y_test,predic):\n",
    "    diff=[]\n",
    "    racio=[]\n",
    "    for i in range(len(y_test)): #para imprimir tabela de previsoes\n",
    "        racio.append( (y_test[i]/predic[i])-1)\n",
    "        diff.append( abs(y_test[i]- predic[i]))\n",
    "        print('valor: %f ---> Previsão: %f Diff: %f Racio: %f' % (y_test[i],predic[i], diff[i],racio[i]))\n",
    "    plt.plot(y_test,color='blue', label='y_test')\n",
    "    plt.plot(predic,color='red', label='prediction') #este deu uma linha em branco\n",
    "    plt.plot(diff,color='green', label='diff')\n",
    "    plt.plot(racio,color='yellow', label='racio')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_():\n",
    "    df = read_csv_dataset(\"advertising-and-sales-data-36-co.csv\")\n",
    "    print(\"df\", df.shape)\n",
    "    print(df.head())\n",
    "    janela = 3 #tamanho da Janela deslizante\n",
    "    #X_train, y_train, X_test, y_test = load_data(df[::-1], janela)# o df[::-1] é o df por ordem inversa\n",
    "    X_train, y_train, X_test, y_test = load_data(df, janela)# o ler o def por ordem normal\n",
    "    print(\"X_train\", X_train.shape)\n",
    "    print(\"y_train\", y_train.shape)\n",
    "    print(\"X_test\", X_test.shape)\n",
    "    print(\"y_test\", y_test.shape)\n",
    "    model = build_model2(janela)\n",
    "    model.fit(X_train, y_train, batch_size=512, epochs=500, validation_split=0.1, verbose=1)\n",
    "    #print_model(model,\"lstm_model.png\")\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    print(model.metrics_names)\n",
    "    p = model.predict(X_test)\n",
    "    predic = np.squeeze(np.asarray(p)) #para transformar uma matriz de uma coluna e n linhas em um np array de n elementos\n",
    "    print_series_prediction(y_test,predic)\n",
    "    # MSE- (Mean square error), RMSE- (root mean square error) - \n",
    "    # o significado de RMSE depende do range da label. para o mesmo range menor é melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato do dataset:  (38, 7)\n",
      "Feature Engineering...\n",
      "Formato do dataset:  (36, 4)\n",
      "df (36, 4)\n",
      "   Month  Advertising  Sales  Year\n",
      "0    1.0         12.0   15.0   1.0\n",
      "1    2.0         20.5   16.0   1.0\n",
      "2    3.0         21.0   18.0   1.0\n",
      "3    4.0         15.5   27.0   1.0\n",
      "4    5.0         15.3   21.0   1.0\n",
      "(32, 4, 4)\n",
      "X_train (24, 3, 4)\n",
      "y_train (24,)\n",
      "X_test (8, 3, 4)\n",
      "y_test (8,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21 samples, validate on 3 samples\n",
      "Epoch 1/500\n",
      "21/21 [==============================] - 5s 216ms/step - loss: 1320.6482 - acc: 0.0000e+00 - val_loss: 505.5221 - val_acc: 0.0000e+00\n",
      "Epoch 2/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1320.3590 - acc: 0.0000e+00 - val_loss: 505.3962 - val_acc: 0.0000e+00\n",
      "Epoch 3/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1320.0638 - acc: 0.0000e+00 - val_loss: 505.2346 - val_acc: 0.0000e+00\n",
      "Epoch 4/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1319.7445 - acc: 0.0000e+00 - val_loss: 505.0278 - val_acc: 0.0000e+00\n",
      "Epoch 5/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1319.2740 - acc: 0.0000e+00 - val_loss: 504.7646 - val_acc: 0.0000e+00\n",
      "Epoch 6/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1318.7390 - acc: 0.0000e+00 - val_loss: 504.4273 - val_acc: 0.0000e+00\n",
      "Epoch 7/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1318.0321 - acc: 0.0000e+00 - val_loss: 503.9989 - val_acc: 0.0000e+00\n",
      "Epoch 8/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1317.2451 - acc: 0.0000e+00 - val_loss: 503.4623 - val_acc: 0.0000e+00\n",
      "Epoch 9/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1316.1416 - acc: 0.0000e+00 - val_loss: 502.8024 - val_acc: 0.0000e+00\n",
      "Epoch 10/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1315.1720 - acc: 0.0000e+00 - val_loss: 502.0027 - val_acc: 0.0000e+00\n",
      "Epoch 11/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1313.6588 - acc: 0.0000e+00 - val_loss: 501.0505 - val_acc: 0.0000e+00\n",
      "Epoch 12/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1311.7021 - acc: 0.0000e+00 - val_loss: 499.9398 - val_acc: 0.0000e+00\n",
      "Epoch 13/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1310.1266 - acc: 0.0000e+00 - val_loss: 498.6652 - val_acc: 0.0000e+00\n",
      "Epoch 14/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1307.8353 - acc: 0.0000e+00 - val_loss: 497.2361 - val_acc: 0.0000e+00\n",
      "Epoch 15/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1305.5000 - acc: 0.0000e+00 - val_loss: 495.7119 - val_acc: 0.0000e+00\n",
      "Epoch 16/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1303.3944 - acc: 0.0000e+00 - val_loss: 494.0962 - val_acc: 0.0000e+00\n",
      "Epoch 17/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1300.0806 - acc: 0.0000e+00 - val_loss: 492.3971 - val_acc: 0.0000e+00\n",
      "Epoch 18/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1297.2085 - acc: 0.0000e+00 - val_loss: 490.6194 - val_acc: 0.0000e+00\n",
      "Epoch 19/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1293.9633 - acc: 0.0000e+00 - val_loss: 488.7617 - val_acc: 0.0000e+00\n",
      "Epoch 20/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1291.7670 - acc: 0.0000e+00 - val_loss: 486.9219 - val_acc: 0.0000e+00\n",
      "Epoch 21/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1287.3221 - acc: 0.0000e+00 - val_loss: 485.0654 - val_acc: 0.0000e+00\n",
      "Epoch 22/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1284.9723 - acc: 0.0000e+00 - val_loss: 483.1899 - val_acc: 0.0000e+00\n",
      "Epoch 23/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1281.1277 - acc: 0.0000e+00 - val_loss: 481.3062 - val_acc: 0.0000e+00\n",
      "Epoch 24/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1278.7543 - acc: 0.0000e+00 - val_loss: 479.3800 - val_acc: 0.0000e+00\n",
      "Epoch 25/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1273.9790 - acc: 0.0000e+00 - val_loss: 477.3796 - val_acc: 0.0000e+00\n",
      "Epoch 26/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1271.8318 - acc: 0.0000e+00 - val_loss: 475.2982 - val_acc: 0.0000e+00\n",
      "Epoch 27/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1267.4055 - acc: 0.0000e+00 - val_loss: 473.1569 - val_acc: 0.0000e+00\n",
      "Epoch 28/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1263.4777 - acc: 0.0000e+00 - val_loss: 470.9485 - val_acc: 0.0000e+00\n",
      "Epoch 29/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1258.7660 - acc: 0.0000e+00 - val_loss: 468.6833 - val_acc: 0.0000e+00\n",
      "Epoch 30/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1255.1848 - acc: 0.0000e+00 - val_loss: 466.3690 - val_acc: 0.0000e+00\n",
      "Epoch 31/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1251.5817 - acc: 0.0000e+00 - val_loss: 463.9953 - val_acc: 0.0000e+00\n",
      "Epoch 32/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1247.4717 - acc: 0.0000e+00 - val_loss: 461.5439 - val_acc: 0.0000e+00\n",
      "Epoch 33/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1241.4696 - acc: 0.0000e+00 - val_loss: 459.0129 - val_acc: 0.0000e+00\n",
      "Epoch 34/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1238.7688 - acc: 0.0000e+00 - val_loss: 456.4051 - val_acc: 0.0000e+00\n",
      "Epoch 35/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1230.9612 - acc: 0.0000e+00 - val_loss: 453.7162 - val_acc: 0.0000e+00\n",
      "Epoch 36/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1227.6006 - acc: 0.0000e+00 - val_loss: 450.9496 - val_acc: 0.0000e+00\n",
      "Epoch 37/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1222.8401 - acc: 0.0000e+00 - val_loss: 448.1069 - val_acc: 0.0000e+00\n",
      "Epoch 38/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1218.6448 - acc: 0.0000e+00 - val_loss: 445.1906 - val_acc: 0.0000e+00\n",
      "Epoch 39/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1211.1506 - acc: 0.0000e+00 - val_loss: 442.1982 - val_acc: 0.0000e+00\n",
      "Epoch 40/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1209.2832 - acc: 0.0000e+00 - val_loss: 439.1357 - val_acc: 0.0000e+00\n",
      "Epoch 41/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1201.6638 - acc: 0.0000e+00 - val_loss: 436.0009 - val_acc: 0.0000e+00\n",
      "Epoch 42/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1197.2178 - acc: 0.0000e+00 - val_loss: 432.7976 - val_acc: 0.0000e+00\n",
      "Epoch 43/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1189.7913 - acc: 0.0000e+00 - val_loss: 429.5243 - val_acc: 0.0000e+00\n",
      "Epoch 44/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1184.0573 - acc: 0.0000e+00 - val_loss: 426.1832 - val_acc: 0.0000e+00\n",
      "Epoch 45/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1179.1847 - acc: 0.0000e+00 - val_loss: 422.7766 - val_acc: 0.0000e+00\n",
      "Epoch 46/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1176.5729 - acc: 0.0476 - val_loss: 419.3107 - val_acc: 0.0000e+00\n",
      "Epoch 47/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1165.0303 - acc: 0.0952 - val_loss: 415.7793 - val_acc: 0.0000e+00\n",
      "Epoch 48/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1158.7957 - acc: 0.0952 - val_loss: 412.1852 - val_acc: 0.0000e+00\n",
      "Epoch 49/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1152.4531 - acc: 0.0952 - val_loss: 408.5304 - val_acc: 0.0000e+00\n",
      "Epoch 50/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1146.3905 - acc: 0.0952 - val_loss: 404.8178 - val_acc: 0.0000e+00\n",
      "Epoch 51/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1142.4797 - acc: 0.0952 - val_loss: 401.0531 - val_acc: 0.0000e+00\n",
      "Epoch 52/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1129.0244 - acc: 0.0952 - val_loss: 397.2297 - val_acc: 0.0000e+00\n",
      "Epoch 53/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1123.2767 - acc: 0.0952 - val_loss: 393.3527 - val_acc: 0.0000e+00\n",
      "Epoch 54/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1117.6854 - acc: 0.0952 - val_loss: 389.4255 - val_acc: 0.0000e+00\n",
      "Epoch 55/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1110.8754 - acc: 0.0000e+00 - val_loss: 385.4517 - val_acc: 0.0000e+00\n",
      "Epoch 56/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1101.8276 - acc: 0.0952 - val_loss: 381.4309 - val_acc: 0.0000e+00\n",
      "Epoch 57/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1091.9928 - acc: 0.0476 - val_loss: 377.3636 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1084.7142 - acc: 0.0000e+00 - val_loss: 373.2539 - val_acc: 0.0000e+00\n",
      "Epoch 59/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1080.3741 - acc: 0.0000e+00 - val_loss: 369.1078 - val_acc: 0.0000e+00\n",
      "Epoch 60/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1074.8149 - acc: 0.0000e+00 - val_loss: 364.9310 - val_acc: 0.0000e+00\n",
      "Epoch 61/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1062.7723 - acc: 0.0000e+00 - val_loss: 360.7207 - val_acc: 0.3333\n",
      "Epoch 62/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1059.8118 - acc: 0.0000e+00 - val_loss: 356.4851 - val_acc: 0.3333\n",
      "Epoch 63/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1047.8099 - acc: 0.0000e+00 - val_loss: 352.2233 - val_acc: 0.3333\n",
      "Epoch 64/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1039.6534 - acc: 0.0000e+00 - val_loss: 347.9381 - val_acc: 0.3333\n",
      "Epoch 65/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1030.1504 - acc: 0.0000e+00 - val_loss: 343.6309 - val_acc: 0.3333\n",
      "Epoch 66/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1013.4401 - acc: 0.0000e+00 - val_loss: 339.2981 - val_acc: 0.3333\n",
      "Epoch 67/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1015.2081 - acc: 0.0000e+00 - val_loss: 334.9536 - val_acc: 0.3333\n",
      "Epoch 68/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 1002.8849 - acc: 0.0000e+00 - val_loss: 330.5959 - val_acc: 0.0000e+00\n",
      "Epoch 69/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 981.1667 - acc: 0.0000e+00 - val_loss: 326.2180 - val_acc: 0.0000e+00\n",
      "Epoch 70/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 981.3102 - acc: 0.0000e+00 - val_loss: 321.8318 - val_acc: 0.0000e+00\n",
      "Epoch 71/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 978.6929 - acc: 0.0000e+00 - val_loss: 317.4479 - val_acc: 0.0000e+00\n",
      "Epoch 72/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 962.2137 - acc: 0.0000e+00 - val_loss: 313.0617 - val_acc: 0.0000e+00\n",
      "Epoch 73/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 959.7151 - acc: 0.0000e+00 - val_loss: 308.6844 - val_acc: 0.0000e+00\n",
      "Epoch 74/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 942.4198 - acc: 0.0000e+00 - val_loss: 304.3124 - val_acc: 0.0000e+00\n",
      "Epoch 75/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 929.6793 - acc: 0.0000e+00 - val_loss: 299.9463 - val_acc: 0.0000e+00\n",
      "Epoch 76/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 933.1708 - acc: 0.0000e+00 - val_loss: 295.6009 - val_acc: 0.0000e+00\n",
      "Epoch 77/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 920.8595 - acc: 0.0000e+00 - val_loss: 291.2748 - val_acc: 0.0000e+00\n",
      "Epoch 78/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 908.2365 - acc: 0.0000e+00 - val_loss: 286.9702 - val_acc: 0.0000e+00\n",
      "Epoch 79/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 914.4675 - acc: 0.0000e+00 - val_loss: 282.7024 - val_acc: 0.0000e+00\n",
      "Epoch 80/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 887.5503 - acc: 0.0000e+00 - val_loss: 278.4614 - val_acc: 0.0000e+00\n",
      "Epoch 81/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 877.0714 - acc: 0.0000e+00 - val_loss: 274.2476 - val_acc: 0.0000e+00\n",
      "Epoch 82/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 868.2832 - acc: 0.0000e+00 - val_loss: 270.0703 - val_acc: 0.0000e+00\n",
      "Epoch 83/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 858.2928 - acc: 0.0000e+00 - val_loss: 265.9301 - val_acc: 0.0000e+00\n",
      "Epoch 84/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 845.3619 - acc: 0.0000e+00 - val_loss: 261.8319 - val_acc: 0.0000e+00\n",
      "Epoch 85/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 834.2594 - acc: 0.0000e+00 - val_loss: 257.7776 - val_acc: 0.0000e+00\n",
      "Epoch 86/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 846.4014 - acc: 0.0000e+00 - val_loss: 253.7831 - val_acc: 0.0000e+00\n",
      "Epoch 87/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 815.7628 - acc: 0.0000e+00 - val_loss: 249.8393 - val_acc: 0.0000e+00\n",
      "Epoch 88/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 808.5671 - acc: 0.0000e+00 - val_loss: 245.9533 - val_acc: 0.0000e+00\n",
      "Epoch 89/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 803.1207 - acc: 0.0000e+00 - val_loss: 242.1287 - val_acc: 0.0000e+00\n",
      "Epoch 90/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 797.9895 - acc: 0.0000e+00 - val_loss: 238.3722 - val_acc: 0.0000e+00\n",
      "Epoch 91/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 775.6257 - acc: 0.0000e+00 - val_loss: 234.6812 - val_acc: 0.0000e+00\n",
      "Epoch 92/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 775.3910 - acc: 0.0000e+00 - val_loss: 231.0620 - val_acc: 0.0000e+00\n",
      "Epoch 93/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 770.7211 - acc: 0.0000e+00 - val_loss: 227.5205 - val_acc: 0.0000e+00\n",
      "Epoch 94/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 751.4730 - acc: 0.0000e+00 - val_loss: 224.0556 - val_acc: 0.0000e+00\n",
      "Epoch 95/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 743.9901 - acc: 0.0476 - val_loss: 220.6714 - val_acc: 0.0000e+00\n",
      "Epoch 96/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 725.2452 - acc: 0.0476 - val_loss: 217.3704 - val_acc: 0.0000e+00\n",
      "Epoch 97/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 723.5707 - acc: 0.0000e+00 - val_loss: 214.1580 - val_acc: 0.0000e+00\n",
      "Epoch 98/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 702.6393 - acc: 0.0000e+00 - val_loss: 211.0342 - val_acc: 0.0000e+00\n",
      "Epoch 99/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 718.4354 - acc: 0.0476 - val_loss: 208.0115 - val_acc: 0.0000e+00\n",
      "Epoch 100/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 697.7381 - acc: 0.0000e+00 - val_loss: 205.0868 - val_acc: 0.0000e+00\n",
      "Epoch 101/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 687.3755 - acc: 0.0476 - val_loss: 202.2619 - val_acc: 0.0000e+00\n",
      "Epoch 102/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 685.2012 - acc: 0.0000e+00 - val_loss: 199.5434 - val_acc: 0.0000e+00\n",
      "Epoch 103/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 660.9922 - acc: 0.0000e+00 - val_loss: 196.9256 - val_acc: 0.0000e+00\n",
      "Epoch 104/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 663.1817 - acc: 0.0000e+00 - val_loss: 194.4163 - val_acc: 0.0000e+00\n",
      "Epoch 105/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 652.9146 - acc: 0.0000e+00 - val_loss: 192.0182 - val_acc: 0.3333\n",
      "Epoch 106/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 643.4618 - acc: 0.0000e+00 - val_loss: 189.7318 - val_acc: 0.3333\n",
      "Epoch 107/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 623.8390 - acc: 0.0000e+00 - val_loss: 187.5585 - val_acc: 0.3333\n",
      "Epoch 108/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 620.1815 - acc: 0.0000e+00 - val_loss: 185.5014 - val_acc: 0.3333\n",
      "Epoch 109/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 614.4777 - acc: 0.0000e+00 - val_loss: 183.5611 - val_acc: 0.0000e+00\n",
      "Epoch 110/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 613.4152 - acc: 0.0000e+00 - val_loss: 181.7439 - val_acc: 0.0000e+00\n",
      "Epoch 111/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 621.0278 - acc: 0.0000e+00 - val_loss: 180.0522 - val_acc: 0.0000e+00\n",
      "Epoch 112/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 582.5795 - acc: 0.0000e+00 - val_loss: 178.4811 - val_acc: 0.0000e+00\n",
      "Epoch 113/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 591.3510 - acc: 0.0000e+00 - val_loss: 177.0357 - val_acc: 0.0000e+00\n",
      "Epoch 114/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 568.9466 - acc: 0.0000e+00 - val_loss: 175.7136 - val_acc: 0.0000e+00\n",
      "Epoch 115/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 537.3501 - acc: 0.0000e+00 - val_loss: 174.5161 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 538.3760 - acc: 0.0000e+00 - val_loss: 173.4454 - val_acc: 0.0000e+00\n",
      "Epoch 117/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 545.0278 - acc: 0.0000e+00 - val_loss: 172.5049 - val_acc: 0.0000e+00\n",
      "Epoch 118/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 556.9446 - acc: 0.0000e+00 - val_loss: 171.6957 - val_acc: 0.0000e+00\n",
      "Epoch 119/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 519.6863 - acc: 0.0000e+00 - val_loss: 171.0147 - val_acc: 0.0000e+00\n",
      "Epoch 120/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 525.8926 - acc: 0.0000e+00 - val_loss: 170.4645 - val_acc: 0.0000e+00\n",
      "Epoch 121/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 501.7916 - acc: 0.0000e+00 - val_loss: 170.0436 - val_acc: 0.0000e+00\n",
      "Epoch 122/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 512.6947 - acc: 0.0000e+00 - val_loss: 169.7531 - val_acc: 0.0000e+00\n",
      "Epoch 123/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 504.8002 - acc: 0.0000e+00 - val_loss: 169.5920 - val_acc: 0.0000e+00\n",
      "Epoch 124/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 496.8139 - acc: 0.0000e+00 - val_loss: 169.5599 - val_acc: 0.0000e+00\n",
      "Epoch 125/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 485.4458 - acc: 0.0000e+00 - val_loss: 169.6561 - val_acc: 0.0000e+00\n",
      "Epoch 126/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 481.3720 - acc: 0.0000e+00 - val_loss: 169.8796 - val_acc: 0.0000e+00\n",
      "Epoch 127/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 463.3372 - acc: 0.0000e+00 - val_loss: 170.2297 - val_acc: 0.0000e+00\n",
      "Epoch 128/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 453.2510 - acc: 0.0000e+00 - val_loss: 170.7059 - val_acc: 0.0000e+00\n",
      "Epoch 129/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 463.6894 - acc: 0.0000e+00 - val_loss: 171.3059 - val_acc: 0.0000e+00\n",
      "Epoch 130/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 464.8305 - acc: 0.0000e+00 - val_loss: 172.0300 - val_acc: 0.0000e+00\n",
      "Epoch 131/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 466.7694 - acc: 0.0000e+00 - val_loss: 172.8731 - val_acc: 0.0000e+00\n",
      "Epoch 132/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 428.4076 - acc: 0.0000e+00 - val_loss: 173.8355 - val_acc: 0.0000e+00\n",
      "Epoch 133/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 440.3973 - acc: 0.0476 - val_loss: 174.9189 - val_acc: 0.0000e+00\n",
      "Epoch 134/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 414.8366 - acc: 0.0952 - val_loss: 176.1187 - val_acc: 0.0000e+00\n",
      "Epoch 135/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 418.4349 - acc: 0.0476 - val_loss: 177.4326 - val_acc: 0.0000e+00\n",
      "Epoch 136/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 424.5826 - acc: 0.0476 - val_loss: 178.8551 - val_acc: 0.0000e+00\n",
      "Epoch 137/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 423.6445 - acc: 0.0476 - val_loss: 180.3850 - val_acc: 0.0000e+00\n",
      "Epoch 138/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 406.2194 - acc: 0.0000e+00 - val_loss: 182.0179 - val_acc: 0.0000e+00\n",
      "Epoch 139/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 400.4218 - acc: 0.0476 - val_loss: 183.7469 - val_acc: 0.0000e+00\n",
      "Epoch 140/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 385.6327 - acc: 0.1429 - val_loss: 185.5723 - val_acc: 0.0000e+00\n",
      "Epoch 141/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 388.9673 - acc: 0.0476 - val_loss: 187.4955 - val_acc: 0.0000e+00\n",
      "Epoch 142/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 421.0869 - acc: 0.0952 - val_loss: 189.4984 - val_acc: 0.0000e+00\n",
      "Epoch 143/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 389.8565 - acc: 0.0952 - val_loss: 191.5777 - val_acc: 0.0000e+00\n",
      "Epoch 144/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 376.8110 - acc: 0.0476 - val_loss: 193.7436 - val_acc: 0.0000e+00\n",
      "Epoch 145/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 369.5888 - acc: 0.0476 - val_loss: 195.9863 - val_acc: 0.0000e+00\n",
      "Epoch 146/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 375.0808 - acc: 0.0000e+00 - val_loss: 198.3128 - val_acc: 0.0000e+00\n",
      "Epoch 147/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 366.0332 - acc: 0.0952 - val_loss: 200.7219 - val_acc: 0.0000e+00\n",
      "Epoch 148/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 360.7880 - acc: 0.0000e+00 - val_loss: 203.1890 - val_acc: 0.0000e+00\n",
      "Epoch 149/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 380.1726 - acc: 0.0000e+00 - val_loss: 205.7212 - val_acc: 0.0000e+00\n",
      "Epoch 150/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 360.4222 - acc: 0.0476 - val_loss: 208.3272 - val_acc: 0.0000e+00\n",
      "Epoch 151/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 365.1718 - acc: 0.0476 - val_loss: 210.9735 - val_acc: 0.0000e+00\n",
      "Epoch 152/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 357.4811 - acc: 0.0000e+00 - val_loss: 213.6627 - val_acc: 0.0000e+00\n",
      "Epoch 153/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 331.3060 - acc: 0.0476 - val_loss: 216.4048 - val_acc: 0.0000e+00\n",
      "Epoch 154/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 370.9785 - acc: 0.0476 - val_loss: 219.1898 - val_acc: 0.0000e+00\n",
      "Epoch 155/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 350.1658 - acc: 0.0000e+00 - val_loss: 222.0052 - val_acc: 0.0000e+00\n",
      "Epoch 156/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 359.2110 - acc: 0.0000e+00 - val_loss: 224.8422 - val_acc: 0.0000e+00\n",
      "Epoch 157/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 334.8918 - acc: 0.0000e+00 - val_loss: 227.7276 - val_acc: 0.0000e+00\n",
      "Epoch 158/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 346.2339 - acc: 0.0000e+00 - val_loss: 230.6549 - val_acc: 0.0000e+00\n",
      "Epoch 159/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 324.4391 - acc: 0.0000e+00 - val_loss: 233.6077 - val_acc: 0.0000e+00\n",
      "Epoch 160/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 334.9351 - acc: 0.0476 - val_loss: 236.5685 - val_acc: 0.0000e+00\n",
      "Epoch 161/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 327.7738 - acc: 0.0476 - val_loss: 239.5410 - val_acc: 0.0000e+00\n",
      "Epoch 162/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 340.3879 - acc: 0.0000e+00 - val_loss: 242.5156 - val_acc: 0.0000e+00\n",
      "Epoch 163/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 324.2112 - acc: 0.0000e+00 - val_loss: 245.5040 - val_acc: 0.0000e+00\n",
      "Epoch 164/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 343.8619 - acc: 0.0000e+00 - val_loss: 248.4805 - val_acc: 0.0000e+00\n",
      "Epoch 165/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 314.6253 - acc: 0.0000e+00 - val_loss: 251.4706 - val_acc: 0.0000e+00\n",
      "Epoch 166/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 325.0844 - acc: 0.0476 - val_loss: 254.4617 - val_acc: 0.0000e+00\n",
      "Epoch 167/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 318.1367 - acc: 0.0476 - val_loss: 257.4431 - val_acc: 0.0000e+00\n",
      "Epoch 168/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 338.3362 - acc: 0.0952 - val_loss: 260.4232 - val_acc: 0.0000e+00\n",
      "Epoch 169/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 346.2097 - acc: 0.0476 - val_loss: 263.4030 - val_acc: 0.0000e+00\n",
      "Epoch 170/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 317.0733 - acc: 0.0952 - val_loss: 266.3303 - val_acc: 0.0000e+00\n",
      "Epoch 171/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 314.3968 - acc: 0.0000e+00 - val_loss: 269.2413 - val_acc: 0.0000e+00\n",
      "Epoch 172/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 317.4448 - acc: 0.0000e+00 - val_loss: 272.1060 - val_acc: 0.0000e+00\n",
      "Epoch 173/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 316.7387 - acc: 0.0952 - val_loss: 274.9554 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 174/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 323.2481 - acc: 0.0476 - val_loss: 277.7654 - val_acc: 0.0000e+00\n",
      "Epoch 175/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 319.1754 - acc: 0.0000e+00 - val_loss: 280.5310 - val_acc: 0.0000e+00\n",
      "Epoch 176/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 313.8761 - acc: 0.0000e+00 - val_loss: 283.2595 - val_acc: 0.0000e+00\n",
      "Epoch 177/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 309.5911 - acc: 0.0476 - val_loss: 285.8995 - val_acc: 0.0000e+00\n",
      "Epoch 178/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 328.1057 - acc: 0.0000e+00 - val_loss: 288.4695 - val_acc: 0.0000e+00\n",
      "Epoch 179/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 317.4827 - acc: 0.0000e+00 - val_loss: 290.9149 - val_acc: 0.0000e+00\n",
      "Epoch 180/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 325.6182 - acc: 0.0000e+00 - val_loss: 293.3072 - val_acc: 0.0000e+00\n",
      "Epoch 181/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 298.7947 - acc: 0.0000e+00 - val_loss: 295.6457 - val_acc: 0.0000e+00\n",
      "Epoch 182/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 312.4988 - acc: 0.0000e+00 - val_loss: 297.8987 - val_acc: 0.0000e+00\n",
      "Epoch 183/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 314.0439 - acc: 0.0000e+00 - val_loss: 300.0922 - val_acc: 0.0000e+00\n",
      "Epoch 184/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 324.2510 - acc: 0.0476 - val_loss: 302.2070 - val_acc: 0.0000e+00\n",
      "Epoch 185/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 316.1572 - acc: 0.0000e+00 - val_loss: 304.2683 - val_acc: 0.0000e+00\n",
      "Epoch 186/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 318.7239 - acc: 0.0000e+00 - val_loss: 306.2788 - val_acc: 0.0000e+00\n",
      "Epoch 187/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 296.3718 - acc: 0.0000e+00 - val_loss: 308.2634 - val_acc: 0.0000e+00\n",
      "Epoch 188/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 283.9247 - acc: 0.0952 - val_loss: 310.2129 - val_acc: 0.0000e+00\n",
      "Epoch 189/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 308.0958 - acc: 0.0000e+00 - val_loss: 312.0821 - val_acc: 0.0000e+00\n",
      "Epoch 190/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 298.0688 - acc: 0.0000e+00 - val_loss: 313.9315 - val_acc: 0.0000e+00\n",
      "Epoch 191/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 323.3456 - acc: 0.0000e+00 - val_loss: 315.6845 - val_acc: 0.0000e+00\n",
      "Epoch 192/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 289.1336 - acc: 0.0000e+00 - val_loss: 317.4007 - val_acc: 0.0000e+00\n",
      "Epoch 193/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 315.7214 - acc: 0.0000e+00 - val_loss: 319.1128 - val_acc: 0.0000e+00\n",
      "Epoch 194/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 308.0278 - acc: 0.0476 - val_loss: 320.7900 - val_acc: 0.0000e+00\n",
      "Epoch 195/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 322.0340 - acc: 0.0476 - val_loss: 322.4596 - val_acc: 0.0000e+00\n",
      "Epoch 196/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 299.3928 - acc: 0.0000e+00 - val_loss: 324.0743 - val_acc: 0.0000e+00\n",
      "Epoch 197/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 312.1375 - acc: 0.0000e+00 - val_loss: 325.6746 - val_acc: 0.0000e+00\n",
      "Epoch 198/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 303.2857 - acc: 0.0000e+00 - val_loss: 327.2198 - val_acc: 0.0000e+00\n",
      "Epoch 199/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 311.8460 - acc: 0.0000e+00 - val_loss: 328.6802 - val_acc: 0.0000e+00\n",
      "Epoch 200/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 310.7908 - acc: 0.0000e+00 - val_loss: 330.1086 - val_acc: 0.0000e+00\n",
      "Epoch 201/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 300.4708 - acc: 0.0000e+00 - val_loss: 331.4610 - val_acc: 0.0000e+00\n",
      "Epoch 202/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 309.6121 - acc: 0.0000e+00 - val_loss: 332.7145 - val_acc: 0.0000e+00\n",
      "Epoch 203/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 344.9631 - acc: 0.0000e+00 - val_loss: 333.8944 - val_acc: 0.0000e+00\n",
      "Epoch 204/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.3737 - acc: 0.0000e+00 - val_loss: 335.0653 - val_acc: 0.0000e+00\n",
      "Epoch 205/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 323.1174 - acc: 0.0000e+00 - val_loss: 336.1270 - val_acc: 0.0000e+00\n",
      "Epoch 206/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 306.8206 - acc: 0.0000e+00 - val_loss: 337.1264 - val_acc: 0.0000e+00\n",
      "Epoch 207/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 322.8283 - acc: 0.0000e+00 - val_loss: 338.0777 - val_acc: 0.0000e+00\n",
      "Epoch 208/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.4435 - acc: 0.0000e+00 - val_loss: 339.0122 - val_acc: 0.0000e+00\n",
      "Epoch 209/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 298.5016 - acc: 0.0476 - val_loss: 339.8649 - val_acc: 0.0000e+00\n",
      "Epoch 210/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 315.4124 - acc: 0.0000e+00 - val_loss: 340.6594 - val_acc: 0.0000e+00\n",
      "Epoch 211/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 279.9713 - acc: 0.0000e+00 - val_loss: 341.3969 - val_acc: 0.0000e+00\n",
      "Epoch 212/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 313.2239 - acc: 0.0000e+00 - val_loss: 342.0480 - val_acc: 0.0000e+00\n",
      "Epoch 213/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 318.0897 - acc: 0.0000e+00 - val_loss: 342.6233 - val_acc: 0.0000e+00\n",
      "Epoch 214/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 309.0660 - acc: 0.0952 - val_loss: 343.1776 - val_acc: 0.0000e+00\n",
      "Epoch 215/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 323.5861 - acc: 0.0000e+00 - val_loss: 343.6744 - val_acc: 0.0000e+00\n",
      "Epoch 216/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 291.9124 - acc: 0.0000e+00 - val_loss: 344.1557 - val_acc: 0.0000e+00\n",
      "Epoch 217/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 315.9492 - acc: 0.0476 - val_loss: 344.6198 - val_acc: 0.0000e+00\n",
      "Epoch 218/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 302.4714 - acc: 0.0000e+00 - val_loss: 345.0576 - val_acc: 0.0000e+00\n",
      "Epoch 219/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 286.3063 - acc: 0.0476 - val_loss: 345.5127 - val_acc: 0.0000e+00\n",
      "Epoch 220/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 282.5701 - acc: 0.0476 - val_loss: 346.0390 - val_acc: 0.0000e+00\n",
      "Epoch 221/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 311.8667 - acc: 0.0000e+00 - val_loss: 346.4767 - val_acc: 0.0000e+00\n",
      "Epoch 222/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 333.5886 - acc: 0.0476 - val_loss: 346.8299 - val_acc: 0.0000e+00\n",
      "Epoch 223/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 296.4119 - acc: 0.0000e+00 - val_loss: 347.1555 - val_acc: 0.0000e+00\n",
      "Epoch 224/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 310.7691 - acc: 0.0000e+00 - val_loss: 347.4780 - val_acc: 0.0000e+00\n",
      "Epoch 225/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 318.3217 - acc: 0.0476 - val_loss: 347.7617 - val_acc: 0.0000e+00\n",
      "Epoch 226/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.3807 - acc: 0.0000e+00 - val_loss: 348.0012 - val_acc: 0.0000e+00\n",
      "Epoch 227/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.0639 - acc: 0.0000e+00 - val_loss: 348.1494 - val_acc: 0.0000e+00\n",
      "Epoch 228/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 320.5219 - acc: 0.0476 - val_loss: 348.3040 - val_acc: 0.0000e+00\n",
      "Epoch 229/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 304.0627 - acc: 0.0000e+00 - val_loss: 348.4492 - val_acc: 0.0000e+00\n",
      "Epoch 230/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 306.8253 - acc: 0.0952 - val_loss: 348.6538 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 289.5681 - acc: 0.0476 - val_loss: 348.8398 - val_acc: 0.0000e+00\n",
      "Epoch 232/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 301.0484 - acc: 0.0952 - val_loss: 349.0258 - val_acc: 0.0000e+00\n",
      "Epoch 233/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 295.5260 - acc: 0.0476 - val_loss: 349.2191 - val_acc: 0.0000e+00\n",
      "Epoch 234/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 279.1755 - acc: 0.0476 - val_loss: 349.4792 - val_acc: 0.0000e+00\n",
      "Epoch 235/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 302.4363 - acc: 0.0000e+00 - val_loss: 349.7598 - val_acc: 0.0000e+00\n",
      "Epoch 236/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.5209 - acc: 0.0476 - val_loss: 349.9749 - val_acc: 0.0000e+00\n",
      "Epoch 237/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 323.6291 - acc: 0.0476 - val_loss: 350.1384 - val_acc: 0.0000e+00\n",
      "Epoch 238/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.9046 - acc: 0.0000e+00 - val_loss: 350.2889 - val_acc: 0.0000e+00\n",
      "Epoch 239/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 307.4884 - acc: 0.0000e+00 - val_loss: 350.3985 - val_acc: 0.0000e+00\n",
      "Epoch 240/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 325.6607 - acc: 0.0000e+00 - val_loss: 350.4555 - val_acc: 0.0000e+00\n",
      "Epoch 241/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 302.6530 - acc: 0.0000e+00 - val_loss: 350.5011 - val_acc: 0.0000e+00\n",
      "Epoch 242/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 304.7926 - acc: 0.0000e+00 - val_loss: 350.4757 - val_acc: 0.0000e+00\n",
      "Epoch 243/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 306.5116 - acc: 0.0000e+00 - val_loss: 350.3473 - val_acc: 0.0000e+00\n",
      "Epoch 244/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 327.7637 - acc: 0.0476 - val_loss: 350.2335 - val_acc: 0.0000e+00\n",
      "Epoch 245/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 314.8162 - acc: 0.0000e+00 - val_loss: 350.1460 - val_acc: 0.0000e+00\n",
      "Epoch 246/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 317.3828 - acc: 0.0000e+00 - val_loss: 350.0541 - val_acc: 0.0000e+00\n",
      "Epoch 247/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 307.3348 - acc: 0.0476 - val_loss: 349.9883 - val_acc: 0.0000e+00\n",
      "Epoch 248/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 306.2979 - acc: 0.0476 - val_loss: 349.8231 - val_acc: 0.0000e+00\n",
      "Epoch 249/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 320.2653 - acc: 0.0000e+00 - val_loss: 349.6761 - val_acc: 0.0000e+00\n",
      "Epoch 250/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 304.5986 - acc: 0.0952 - val_loss: 349.5572 - val_acc: 0.0000e+00\n",
      "Epoch 251/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 321.4151 - acc: 0.0000e+00 - val_loss: 349.3658 - val_acc: 0.0000e+00\n",
      "Epoch 252/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 282.7350 - acc: 0.0000e+00 - val_loss: 349.2657 - val_acc: 0.0000e+00\n",
      "Epoch 253/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 310.5576 - acc: 0.0000e+00 - val_loss: 349.2012 - val_acc: 0.0000e+00\n",
      "Epoch 254/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 311.1954 - acc: 0.0476 - val_loss: 349.1073 - val_acc: 0.0000e+00\n",
      "Epoch 255/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 319.7869 - acc: 0.0000e+00 - val_loss: 349.0324 - val_acc: 0.0000e+00\n",
      "Epoch 256/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 302.1160 - acc: 0.0000e+00 - val_loss: 348.9901 - val_acc: 0.0000e+00\n",
      "Epoch 257/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 321.4101 - acc: 0.0000e+00 - val_loss: 348.9258 - val_acc: 0.0000e+00\n",
      "Epoch 258/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 304.3143 - acc: 0.0476 - val_loss: 348.8199 - val_acc: 0.0000e+00\n",
      "Epoch 259/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 296.9385 - acc: 0.0000e+00 - val_loss: 348.6864 - val_acc: 0.0000e+00\n",
      "Epoch 260/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 290.9379 - acc: 0.0000e+00 - val_loss: 348.6318 - val_acc: 0.0000e+00\n",
      "Epoch 261/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 344.5003 - acc: 0.0476 - val_loss: 348.5027 - val_acc: 0.0000e+00\n",
      "Epoch 262/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 314.8564 - acc: 0.0952 - val_loss: 348.4399 - val_acc: 0.0000e+00\n",
      "Epoch 263/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 282.6775 - acc: 0.0000e+00 - val_loss: 348.4127 - val_acc: 0.0000e+00\n",
      "Epoch 264/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 295.7461 - acc: 0.0476 - val_loss: 348.3761 - val_acc: 0.0000e+00\n",
      "Epoch 265/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 288.7586 - acc: 0.0952 - val_loss: 348.4891 - val_acc: 0.0000e+00\n",
      "Epoch 266/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 292.6612 - acc: 0.0476 - val_loss: 348.6813 - val_acc: 0.0000e+00\n",
      "Epoch 267/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 321.4613 - acc: 0.0000e+00 - val_loss: 348.8587 - val_acc: 0.0000e+00\n",
      "Epoch 268/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 301.2533 - acc: 0.0476 - val_loss: 349.0133 - val_acc: 0.0000e+00\n",
      "Epoch 269/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 302.7624 - acc: 0.0476 - val_loss: 349.2079 - val_acc: 0.0000e+00\n",
      "Epoch 270/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 329.1256 - acc: 0.0000e+00 - val_loss: 349.3426 - val_acc: 0.0000e+00\n",
      "Epoch 271/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.7127 - acc: 0.0000e+00 - val_loss: 349.4510 - val_acc: 0.0000e+00\n",
      "Epoch 272/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 317.1533 - acc: 0.0476 - val_loss: 349.5933 - val_acc: 0.0000e+00\n",
      "Epoch 273/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 307.4286 - acc: 0.0000e+00 - val_loss: 349.6902 - val_acc: 0.0000e+00\n",
      "Epoch 274/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 299.8037 - acc: 0.0000e+00 - val_loss: 349.8324 - val_acc: 0.0000e+00\n",
      "Epoch 275/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 334.2613 - acc: 0.0000e+00 - val_loss: 349.8695 - val_acc: 0.0000e+00\n",
      "Epoch 276/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 310.9897 - acc: 0.0000e+00 - val_loss: 349.9495 - val_acc: 0.0000e+00\n",
      "Epoch 277/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 296.1605 - acc: 0.0000e+00 - val_loss: 350.0072 - val_acc: 0.0000e+00\n",
      "Epoch 278/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 307.3618 - acc: 0.0000e+00 - val_loss: 350.1128 - val_acc: 0.0000e+00\n",
      "Epoch 279/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 311.2220 - acc: 0.0000e+00 - val_loss: 350.2430 - val_acc: 0.0000e+00\n",
      "Epoch 280/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 300.4375 - acc: 0.0000e+00 - val_loss: 350.4373 - val_acc: 0.0000e+00\n",
      "Epoch 281/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 313.5540 - acc: 0.0000e+00 - val_loss: 350.6461 - val_acc: 0.0000e+00\n",
      "Epoch 282/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 275.3471 - acc: 0.0476 - val_loss: 350.8240 - val_acc: 0.0000e+00\n",
      "Epoch 283/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 294.7968 - acc: 0.0476 - val_loss: 351.0589 - val_acc: 0.0000e+00\n",
      "Epoch 284/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 325.5518 - acc: 0.0000e+00 - val_loss: 351.3184 - val_acc: 0.0000e+00\n",
      "Epoch 285/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 323.0909 - acc: 0.0000e+00 - val_loss: 351.4967 - val_acc: 0.0000e+00\n",
      "Epoch 286/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 294.9698 - acc: 0.0000e+00 - val_loss: 351.6719 - val_acc: 0.0000e+00\n",
      "Epoch 287/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 337.1811 - acc: 0.0000e+00 - val_loss: 351.7518 - val_acc: 0.0000e+00\n",
      "Epoch 288/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 316.5113 - acc: 0.0476 - val_loss: 351.8174 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 329.1768 - acc: 0.0000e+00 - val_loss: 351.7878 - val_acc: 0.0000e+00\n",
      "Epoch 290/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 312.6944 - acc: 0.0000e+00 - val_loss: 351.7610 - val_acc: 0.0000e+00\n",
      "Epoch 291/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 300.3050 - acc: 0.0000e+00 - val_loss: 351.7478 - val_acc: 0.0000e+00\n",
      "Epoch 292/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.5659 - acc: 0.0476 - val_loss: 351.7081 - val_acc: 0.0000e+00\n",
      "Epoch 293/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 304.6234 - acc: 0.0000e+00 - val_loss: 351.5867 - val_acc: 0.0000e+00\n",
      "Epoch 294/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 328.3099 - acc: 0.0476 - val_loss: 351.3912 - val_acc: 0.0000e+00\n",
      "Epoch 295/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 271.4427 - acc: 0.0476 - val_loss: 351.3683 - val_acc: 0.0000e+00\n",
      "Epoch 296/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 322.7582 - acc: 0.0000e+00 - val_loss: 351.3478 - val_acc: 0.0000e+00\n",
      "Epoch 297/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 299.3029 - acc: 0.0000e+00 - val_loss: 351.3680 - val_acc: 0.0000e+00\n",
      "Epoch 298/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 316.0814 - acc: 0.0476 - val_loss: 351.2952 - val_acc: 0.0000e+00\n",
      "Epoch 299/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 291.7894 - acc: 0.0000e+00 - val_loss: 351.2155 - val_acc: 0.0000e+00\n",
      "Epoch 300/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 292.7544 - acc: 0.0476 - val_loss: 351.2007 - val_acc: 0.0000e+00\n",
      "Epoch 301/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 292.0778 - acc: 0.0000e+00 - val_loss: 351.2322 - val_acc: 0.0000e+00\n",
      "Epoch 302/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 324.8377 - acc: 0.0000e+00 - val_loss: 351.2359 - val_acc: 0.0000e+00\n",
      "Epoch 303/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 297.9938 - acc: 0.0000e+00 - val_loss: 351.2227 - val_acc: 0.0000e+00\n",
      "Epoch 304/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 275.5391 - acc: 0.0476 - val_loss: 351.2605 - val_acc: 0.0000e+00\n",
      "Epoch 305/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 278.8061 - acc: 0.0476 - val_loss: 351.2259 - val_acc: 0.0000e+00\n",
      "Epoch 306/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 295.7872 - acc: 0.0476 - val_loss: 351.1988 - val_acc: 0.0000e+00\n",
      "Epoch 307/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 314.3463 - acc: 0.0476 - val_loss: 351.1117 - val_acc: 0.0000e+00\n",
      "Epoch 308/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 289.6629 - acc: 0.0000e+00 - val_loss: 351.0475 - val_acc: 0.0000e+00\n",
      "Epoch 309/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 297.5780 - acc: 0.0000e+00 - val_loss: 351.0092 - val_acc: 0.0000e+00\n",
      "Epoch 310/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 309.4928 - acc: 0.0476 - val_loss: 351.0002 - val_acc: 0.0000e+00\n",
      "Epoch 311/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 287.8013 - acc: 0.0000e+00 - val_loss: 350.9822 - val_acc: 0.0000e+00\n",
      "Epoch 312/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 331.5340 - acc: 0.0476 - val_loss: 350.9196 - val_acc: 0.0000e+00\n",
      "Epoch 313/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 284.4798 - acc: 0.0000e+00 - val_loss: 350.9338 - val_acc: 0.0000e+00\n",
      "Epoch 314/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 312.7368 - acc: 0.0000e+00 - val_loss: 351.0111 - val_acc: 0.0000e+00\n",
      "Epoch 315/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 285.1982 - acc: 0.0476 - val_loss: 351.1198 - val_acc: 0.0000e+00\n",
      "Epoch 316/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 319.7929 - acc: 0.0000e+00 - val_loss: 351.1836 - val_acc: 0.0000e+00\n",
      "Epoch 317/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 322.8237 - acc: 0.0000e+00 - val_loss: 351.2617 - val_acc: 0.0000e+00\n",
      "Epoch 318/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 314.4915 - acc: 0.0000e+00 - val_loss: 351.3391 - val_acc: 0.0000e+00\n",
      "Epoch 319/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.3137 - acc: 0.0000e+00 - val_loss: 351.4522 - val_acc: 0.0000e+00\n",
      "Epoch 320/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 291.0256 - acc: 0.0000e+00 - val_loss: 351.5671 - val_acc: 0.0000e+00\n",
      "Epoch 321/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 302.1510 - acc: 0.0000e+00 - val_loss: 351.7246 - val_acc: 0.0000e+00\n",
      "Epoch 322/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 301.2111 - acc: 0.0476 - val_loss: 351.8650 - val_acc: 0.0000e+00\n",
      "Epoch 323/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 301.4921 - acc: 0.0000e+00 - val_loss: 352.0384 - val_acc: 0.0000e+00\n",
      "Epoch 324/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 297.2979 - acc: 0.0476 - val_loss: 352.2745 - val_acc: 0.0000e+00\n",
      "Epoch 325/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 318.0771 - acc: 0.0952 - val_loss: 352.4839 - val_acc: 0.0000e+00\n",
      "Epoch 326/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 325.7658 - acc: 0.0000e+00 - val_loss: 352.6060 - val_acc: 0.0000e+00\n",
      "Epoch 327/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 293.8714 - acc: 0.0000e+00 - val_loss: 352.7474 - val_acc: 0.0000e+00\n",
      "Epoch 328/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 339.3891 - acc: 0.0000e+00 - val_loss: 352.8788 - val_acc: 0.0000e+00\n",
      "Epoch 329/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 295.2235 - acc: 0.0000e+00 - val_loss: 353.0554 - val_acc: 0.0000e+00\n",
      "Epoch 330/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 306.4940 - acc: 0.0000e+00 - val_loss: 353.1407 - val_acc: 0.0000e+00\n",
      "Epoch 331/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 329.1766 - acc: 0.0000e+00 - val_loss: 353.1280 - val_acc: 0.0000e+00\n",
      "Epoch 332/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 297.7305 - acc: 0.0000e+00 - val_loss: 353.0883 - val_acc: 0.0000e+00\n",
      "Epoch 333/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 326.8862 - acc: 0.0000e+00 - val_loss: 352.8216 - val_acc: 0.0000e+00\n",
      "Epoch 334/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 286.7206 - acc: 0.0000e+00 - val_loss: 352.5863 - val_acc: 0.0000e+00\n",
      "Epoch 335/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 308.7073 - acc: 0.0000e+00 - val_loss: 352.3213 - val_acc: 0.0000e+00\n",
      "Epoch 336/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 293.0585 - acc: 0.0000e+00 - val_loss: 352.1365 - val_acc: 0.0000e+00\n",
      "Epoch 337/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 312.1381 - acc: 0.0000e+00 - val_loss: 351.9983 - val_acc: 0.0000e+00\n",
      "Epoch 338/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 290.9398 - acc: 0.0476 - val_loss: 351.9211 - val_acc: 0.0000e+00\n",
      "Epoch 339/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 304.6147 - acc: 0.0476 - val_loss: 351.8982 - val_acc: 0.0000e+00\n",
      "Epoch 340/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 312.5981 - acc: 0.0000e+00 - val_loss: 351.7950 - val_acc: 0.0000e+00\n",
      "Epoch 341/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 306.0647 - acc: 0.0000e+00 - val_loss: 351.6642 - val_acc: 0.0000e+00\n",
      "Epoch 342/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 312.0182 - acc: 0.0000e+00 - val_loss: 351.4344 - val_acc: 0.0000e+00\n",
      "Epoch 343/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 319.0538 - acc: 0.0000e+00 - val_loss: 351.1893 - val_acc: 0.0000e+00\n",
      "Epoch 344/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 324.1487 - acc: 0.0952 - val_loss: 350.8893 - val_acc: 0.0000e+00\n",
      "Epoch 345/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 292.1039 - acc: 0.0000e+00 - val_loss: 350.5952 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 298.0005 - acc: 0.0000e+00 - val_loss: 350.3368 - val_acc: 0.0000e+00\n",
      "Epoch 347/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 331.3475 - acc: 0.0000e+00 - val_loss: 349.9896 - val_acc: 0.0000e+00\n",
      "Epoch 348/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 303.9186 - acc: 0.0000e+00 - val_loss: 349.7144 - val_acc: 0.0000e+00\n",
      "Epoch 349/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 328.8676 - acc: 0.0000e+00 - val_loss: 349.4095 - val_acc: 0.0000e+00\n",
      "Epoch 350/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.9662 - acc: 0.0476 - val_loss: 349.1781 - val_acc: 0.0000e+00\n",
      "Epoch 351/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 324.0689 - acc: 0.0476 - val_loss: 348.8705 - val_acc: 0.0000e+00\n",
      "Epoch 352/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 294.8986 - acc: 0.0000e+00 - val_loss: 348.6625 - val_acc: 0.0000e+00\n",
      "Epoch 353/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 325.5316 - acc: 0.0476 - val_loss: 348.4242 - val_acc: 0.0000e+00\n",
      "Epoch 354/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 327.7224 - acc: 0.0476 - val_loss: 348.1848 - val_acc: 0.0000e+00\n",
      "Epoch 355/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 289.6556 - acc: 0.0000e+00 - val_loss: 348.0735 - val_acc: 0.0000e+00\n",
      "Epoch 356/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 306.9689 - acc: 0.0000e+00 - val_loss: 348.0244 - val_acc: 0.0000e+00\n",
      "Epoch 357/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 289.7509 - acc: 0.0476 - val_loss: 347.9973 - val_acc: 0.0000e+00\n",
      "Epoch 358/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 304.0331 - acc: 0.0000e+00 - val_loss: 348.0651 - val_acc: 0.0000e+00\n",
      "Epoch 359/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 298.8737 - acc: 0.0000e+00 - val_loss: 348.1749 - val_acc: 0.0000e+00\n",
      "Epoch 360/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 275.0968 - acc: 0.0000e+00 - val_loss: 348.3082 - val_acc: 0.0000e+00\n",
      "Epoch 361/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 316.6385 - acc: 0.0000e+00 - val_loss: 348.4542 - val_acc: 0.0000e+00\n",
      "Epoch 362/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 306.0512 - acc: 0.0000e+00 - val_loss: 348.6264 - val_acc: 0.0000e+00\n",
      "Epoch 363/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 300.2959 - acc: 0.0476 - val_loss: 348.7906 - val_acc: 0.0000e+00\n",
      "Epoch 364/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 310.6206 - acc: 0.0000e+00 - val_loss: 348.9673 - val_acc: 0.0000e+00\n",
      "Epoch 365/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 311.9166 - acc: 0.0000e+00 - val_loss: 349.1295 - val_acc: 0.0000e+00\n",
      "Epoch 366/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 312.1643 - acc: 0.0000e+00 - val_loss: 349.2190 - val_acc: 0.0000e+00\n",
      "Epoch 367/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 294.1915 - acc: 0.0476 - val_loss: 349.3098 - val_acc: 0.0000e+00\n",
      "Epoch 368/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 313.8194 - acc: 0.0000e+00 - val_loss: 349.3958 - val_acc: 0.0000e+00\n",
      "Epoch 369/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 304.2281 - acc: 0.0000e+00 - val_loss: 349.5193 - val_acc: 0.0000e+00\n",
      "Epoch 370/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 307.9949 - acc: 0.0000e+00 - val_loss: 349.5949 - val_acc: 0.0000e+00\n",
      "Epoch 371/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 295.7514 - acc: 0.0000e+00 - val_loss: 349.6939 - val_acc: 0.0000e+00\n",
      "Epoch 372/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 298.2672 - acc: 0.0000e+00 - val_loss: 349.7462 - val_acc: 0.0000e+00\n",
      "Epoch 373/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 300.9078 - acc: 0.0000e+00 - val_loss: 349.8399 - val_acc: 0.0000e+00\n",
      "Epoch 374/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.6548 - acc: 0.0476 - val_loss: 349.8899 - val_acc: 0.0000e+00\n",
      "Epoch 375/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 335.0017 - acc: 0.0000e+00 - val_loss: 349.9218 - val_acc: 0.0000e+00\n",
      "Epoch 376/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 319.0659 - acc: 0.0476 - val_loss: 349.9001 - val_acc: 0.0000e+00\n",
      "Epoch 377/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 324.6170 - acc: 0.0000e+00 - val_loss: 349.8695 - val_acc: 0.0000e+00\n",
      "Epoch 378/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 301.5564 - acc: 0.0000e+00 - val_loss: 349.8896 - val_acc: 0.0000e+00\n",
      "Epoch 379/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 295.5748 - acc: 0.0476 - val_loss: 349.8894 - val_acc: 0.0000e+00\n",
      "Epoch 380/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 306.3062 - acc: 0.0000e+00 - val_loss: 349.9467 - val_acc: 0.0000e+00\n",
      "Epoch 381/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 303.9989 - acc: 0.0476 - val_loss: 349.9829 - val_acc: 0.0000e+00\n",
      "Epoch 382/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 288.8894 - acc: 0.0000e+00 - val_loss: 350.0826 - val_acc: 0.0000e+00\n",
      "Epoch 383/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 279.0825 - acc: 0.0000e+00 - val_loss: 350.2694 - val_acc: 0.0000e+00\n",
      "Epoch 384/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 312.9607 - acc: 0.0476 - val_loss: 350.4408 - val_acc: 0.0000e+00\n",
      "Epoch 385/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.0398 - acc: 0.0476 - val_loss: 350.5971 - val_acc: 0.0000e+00\n",
      "Epoch 386/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 317.9263 - acc: 0.0000e+00 - val_loss: 350.7623 - val_acc: 0.0000e+00\n",
      "Epoch 387/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.2901 - acc: 0.0000e+00 - val_loss: 350.9484 - val_acc: 0.0000e+00\n",
      "Epoch 388/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 308.3595 - acc: 0.0000e+00 - val_loss: 351.0118 - val_acc: 0.0000e+00\n",
      "Epoch 389/500\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 311.2260 - acc: 0.0000e+00 - val_loss: 351.0559 - val_acc: 0.0000e+00\n",
      "Epoch 390/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 317.9364 - acc: 0.0000e+00 - val_loss: 351.1527 - val_acc: 0.0000e+00\n",
      "Epoch 391/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 299.9834 - acc: 0.0000e+00 - val_loss: 351.1738 - val_acc: 0.0000e+00\n",
      "Epoch 392/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 316.5440 - acc: 0.0476 - val_loss: 351.2074 - val_acc: 0.0000e+00\n",
      "Epoch 393/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 310.1248 - acc: 0.0000e+00 - val_loss: 351.2144 - val_acc: 0.0000e+00\n",
      "Epoch 394/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.0880 - acc: 0.0000e+00 - val_loss: 351.2264 - val_acc: 0.0000e+00\n",
      "Epoch 395/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 319.2752 - acc: 0.0476 - val_loss: 351.2345 - val_acc: 0.0000e+00\n",
      "Epoch 396/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 291.2386 - acc: 0.0476 - val_loss: 351.2876 - val_acc: 0.0000e+00\n",
      "Epoch 397/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 296.9221 - acc: 0.0000e+00 - val_loss: 351.4349 - val_acc: 0.0000e+00\n",
      "Epoch 398/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 297.0893 - acc: 0.0000e+00 - val_loss: 351.6169 - val_acc: 0.0000e+00\n",
      "Epoch 399/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 306.2472 - acc: 0.0000e+00 - val_loss: 351.8232 - val_acc: 0.0000e+00\n",
      "Epoch 400/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 320.1017 - acc: 0.0476 - val_loss: 352.0051 - val_acc: 0.0000e+00\n",
      "Epoch 401/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 286.9322 - acc: 0.0000e+00 - val_loss: 352.0925 - val_acc: 0.0000e+00\n",
      "Epoch 402/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 330.8369 - acc: 0.0000e+00 - val_loss: 352.0719 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 302.9280 - acc: 0.0000e+00 - val_loss: 352.0488 - val_acc: 0.0000e+00\n",
      "Epoch 404/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 301.3987 - acc: 0.0000e+00 - val_loss: 352.0156 - val_acc: 0.0000e+00\n",
      "Epoch 405/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 308.6067 - acc: 0.0000e+00 - val_loss: 351.9702 - val_acc: 0.0000e+00\n",
      "Epoch 406/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 320.0605 - acc: 0.0476 - val_loss: 351.8830 - val_acc: 0.0000e+00\n",
      "Epoch 407/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 302.9664 - acc: 0.0000e+00 - val_loss: 351.7603 - val_acc: 0.0000e+00\n",
      "Epoch 408/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 288.0062 - acc: 0.0952 - val_loss: 351.7840 - val_acc: 0.0000e+00\n",
      "Epoch 409/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 281.3710 - acc: 0.0000e+00 - val_loss: 351.8462 - val_acc: 0.0000e+00\n",
      "Epoch 410/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 294.3653 - acc: 0.0000e+00 - val_loss: 351.9940 - val_acc: 0.0000e+00\n",
      "Epoch 411/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 297.8542 - acc: 0.0000e+00 - val_loss: 352.1957 - val_acc: 0.0000e+00\n",
      "Epoch 412/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 332.1806 - acc: 0.0000e+00 - val_loss: 352.2898 - val_acc: 0.0000e+00\n",
      "Epoch 413/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 299.4763 - acc: 0.0000e+00 - val_loss: 352.4383 - val_acc: 0.0000e+00\n",
      "Epoch 414/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 306.4780 - acc: 0.0000e+00 - val_loss: 352.5852 - val_acc: 0.0000e+00\n",
      "Epoch 415/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 314.2478 - acc: 0.0000e+00 - val_loss: 352.5929 - val_acc: 0.0000e+00\n",
      "Epoch 416/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 319.4283 - acc: 0.0000e+00 - val_loss: 352.5054 - val_acc: 0.0000e+00\n",
      "Epoch 417/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 333.5373 - acc: 0.0000e+00 - val_loss: 352.3335 - val_acc: 0.0000e+00\n",
      "Epoch 418/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 293.1748 - acc: 0.0000e+00 - val_loss: 352.1469 - val_acc: 0.0000e+00\n",
      "Epoch 419/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 286.4323 - acc: 0.0000e+00 - val_loss: 351.9607 - val_acc: 0.0000e+00\n",
      "Epoch 420/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 309.6013 - acc: 0.0476 - val_loss: 351.6797 - val_acc: 0.0000e+00\n",
      "Epoch 421/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 304.6705 - acc: 0.0952 - val_loss: 351.5049 - val_acc: 0.0000e+00\n",
      "Epoch 422/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 284.9152 - acc: 0.0476 - val_loss: 351.4131 - val_acc: 0.0000e+00\n",
      "Epoch 423/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 300.6054 - acc: 0.0952 - val_loss: 351.3999 - val_acc: 0.0000e+00\n",
      "Epoch 424/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 271.5915 - acc: 0.0476 - val_loss: 351.4521 - val_acc: 0.0000e+00\n",
      "Epoch 425/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.9559 - acc: 0.0000e+00 - val_loss: 351.4940 - val_acc: 0.0000e+00\n",
      "Epoch 426/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 320.3083 - acc: 0.0000e+00 - val_loss: 351.4406 - val_acc: 0.0000e+00\n",
      "Epoch 427/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 302.2435 - acc: 0.0476 - val_loss: 351.3083 - val_acc: 0.0000e+00\n",
      "Epoch 428/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 322.0234 - acc: 0.0000e+00 - val_loss: 351.0782 - val_acc: 0.0000e+00\n",
      "Epoch 429/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.4689 - acc: 0.0000e+00 - val_loss: 350.8855 - val_acc: 0.0000e+00\n",
      "Epoch 430/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 325.9481 - acc: 0.0000e+00 - val_loss: 350.7484 - val_acc: 0.0000e+00\n",
      "Epoch 431/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 315.4369 - acc: 0.0000e+00 - val_loss: 350.5928 - val_acc: 0.0000e+00\n",
      "Epoch 432/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 302.9239 - acc: 0.0476 - val_loss: 350.3670 - val_acc: 0.0000e+00\n",
      "Epoch 433/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 286.3369 - acc: 0.0000e+00 - val_loss: 350.2439 - val_acc: 0.0000e+00\n",
      "Epoch 434/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 280.9938 - acc: 0.0000e+00 - val_loss: 350.2631 - val_acc: 0.0000e+00\n",
      "Epoch 435/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 297.1376 - acc: 0.0476 - val_loss: 350.3440 - val_acc: 0.0000e+00\n",
      "Epoch 436/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 321.6595 - acc: 0.0476 - val_loss: 350.3901 - val_acc: 0.0000e+00\n",
      "Epoch 437/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 305.8535 - acc: 0.0476 - val_loss: 350.3905 - val_acc: 0.0000e+00\n",
      "Epoch 438/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 286.3481 - acc: 0.0000e+00 - val_loss: 350.4611 - val_acc: 0.0000e+00\n",
      "Epoch 439/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 347.5718 - acc: 0.0000e+00 - val_loss: 350.4753 - val_acc: 0.0000e+00\n",
      "Epoch 440/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 284.6081 - acc: 0.0000e+00 - val_loss: 350.5592 - val_acc: 0.0000e+00\n",
      "Epoch 441/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 320.4801 - acc: 0.0476 - val_loss: 350.6029 - val_acc: 0.0000e+00\n",
      "Epoch 442/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 291.0591 - acc: 0.0000e+00 - val_loss: 350.8073 - val_acc: 0.0000e+00\n",
      "Epoch 443/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 296.6604 - acc: 0.0000e+00 - val_loss: 351.0396 - val_acc: 0.0000e+00\n",
      "Epoch 444/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 326.3439 - acc: 0.0000e+00 - val_loss: 351.2786 - val_acc: 0.0000e+00\n",
      "Epoch 445/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 285.4933 - acc: 0.0952 - val_loss: 351.5312 - val_acc: 0.0000e+00\n",
      "Epoch 446/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 291.5338 - acc: 0.0000e+00 - val_loss: 351.8086 - val_acc: 0.0000e+00\n",
      "Epoch 447/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 317.3721 - acc: 0.0000e+00 - val_loss: 351.9930 - val_acc: 0.0000e+00\n",
      "Epoch 448/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 311.1671 - acc: 0.0000e+00 - val_loss: 352.1251 - val_acc: 0.0000e+00\n",
      "Epoch 449/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 323.1493 - acc: 0.0000e+00 - val_loss: 352.1933 - val_acc: 0.0000e+00\n",
      "Epoch 450/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 315.0411 - acc: 0.0000e+00 - val_loss: 352.2682 - val_acc: 0.0000e+00\n",
      "Epoch 451/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 309.1022 - acc: 0.0000e+00 - val_loss: 352.2693 - val_acc: 0.0000e+00\n",
      "Epoch 452/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 299.5635 - acc: 0.0476 - val_loss: 352.2005 - val_acc: 0.0000e+00\n",
      "Epoch 453/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 302.9257 - acc: 0.0476 - val_loss: 352.1163 - val_acc: 0.0000e+00\n",
      "Epoch 454/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 324.8695 - acc: 0.0000e+00 - val_loss: 351.9957 - val_acc: 0.0000e+00\n",
      "Epoch 455/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 310.4824 - acc: 0.0476 - val_loss: 351.8267 - val_acc: 0.0000e+00\n",
      "Epoch 456/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 297.1894 - acc: 0.0000e+00 - val_loss: 351.7440 - val_acc: 0.0000e+00\n",
      "Epoch 457/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 314.3413 - acc: 0.0000e+00 - val_loss: 351.6770 - val_acc: 0.0000e+00\n",
      "Epoch 458/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 278.0311 - acc: 0.0000e+00 - val_loss: 351.7157 - val_acc: 0.0000e+00\n",
      "Epoch 459/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 313.1843 - acc: 0.0476 - val_loss: 351.7123 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 312.2913 - acc: 0.0000e+00 - val_loss: 351.7634 - val_acc: 0.0000e+00\n",
      "Epoch 461/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 304.8087 - acc: 0.0000e+00 - val_loss: 351.8260 - val_acc: 0.0000e+00\n",
      "Epoch 462/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 314.2109 - acc: 0.0476 - val_loss: 351.8159 - val_acc: 0.0000e+00\n",
      "Epoch 463/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 293.2809 - acc: 0.0000e+00 - val_loss: 351.8684 - val_acc: 0.0000e+00\n",
      "Epoch 464/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 313.7341 - acc: 0.0000e+00 - val_loss: 351.7929 - val_acc: 0.0000e+00\n",
      "Epoch 465/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 332.5804 - acc: 0.0000e+00 - val_loss: 351.5697 - val_acc: 0.0000e+00\n",
      "Epoch 466/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 308.7318 - acc: 0.0000e+00 - val_loss: 351.3429 - val_acc: 0.0000e+00\n",
      "Epoch 467/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 308.0507 - acc: 0.0000e+00 - val_loss: 351.1497 - val_acc: 0.0000e+00\n",
      "Epoch 468/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 321.7433 - acc: 0.0000e+00 - val_loss: 350.8282 - val_acc: 0.0000e+00\n",
      "Epoch 469/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 307.7201 - acc: 0.0000e+00 - val_loss: 350.4810 - val_acc: 0.0000e+00\n",
      "Epoch 470/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 310.9626 - acc: 0.0476 - val_loss: 350.1053 - val_acc: 0.0000e+00\n",
      "Epoch 471/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 281.4101 - acc: 0.0000e+00 - val_loss: 349.8256 - val_acc: 0.0000e+00\n",
      "Epoch 472/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 309.9749 - acc: 0.0000e+00 - val_loss: 349.4802 - val_acc: 0.0000e+00\n",
      "Epoch 473/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 294.2201 - acc: 0.0000e+00 - val_loss: 349.2515 - val_acc: 0.0000e+00\n",
      "Epoch 474/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 293.5573 - acc: 0.0000e+00 - val_loss: 349.0497 - val_acc: 0.0000e+00\n",
      "Epoch 475/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 309.7715 - acc: 0.0476 - val_loss: 348.9650 - val_acc: 0.0000e+00\n",
      "Epoch 476/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 275.8436 - acc: 0.0476 - val_loss: 348.9608 - val_acc: 0.0000e+00\n",
      "Epoch 477/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 316.9662 - acc: 0.0476 - val_loss: 348.8869 - val_acc: 0.0000e+00\n",
      "Epoch 478/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 303.7338 - acc: 0.0952 - val_loss: 348.8130 - val_acc: 0.0000e+00\n",
      "Epoch 479/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 325.0109 - acc: 0.0000e+00 - val_loss: 348.7077 - val_acc: 0.0000e+00\n",
      "Epoch 480/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 291.3856 - acc: 0.0000e+00 - val_loss: 348.6182 - val_acc: 0.0000e+00\n",
      "Epoch 481/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 315.2302 - acc: 0.0000e+00 - val_loss: 348.4581 - val_acc: 0.0000e+00\n",
      "Epoch 482/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 303.2714 - acc: 0.0000e+00 - val_loss: 348.3460 - val_acc: 0.0000e+00\n",
      "Epoch 483/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 325.0507 - acc: 0.0000e+00 - val_loss: 348.3109 - val_acc: 0.0000e+00\n",
      "Epoch 484/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 298.6251 - acc: 0.0000e+00 - val_loss: 348.1961 - val_acc: 0.0000e+00\n",
      "Epoch 485/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 309.5525 - acc: 0.0000e+00 - val_loss: 348.0582 - val_acc: 0.0000e+00\n",
      "Epoch 486/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 319.6205 - acc: 0.0476 - val_loss: 347.9629 - val_acc: 0.0000e+00\n",
      "Epoch 487/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 303.0061 - acc: 0.0000e+00 - val_loss: 347.9215 - val_acc: 0.0000e+00\n",
      "Epoch 488/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 266.3112 - acc: 0.0000e+00 - val_loss: 348.0063 - val_acc: 0.0000e+00\n",
      "Epoch 489/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 329.3289 - acc: 0.0476 - val_loss: 348.0468 - val_acc: 0.0000e+00\n",
      "Epoch 490/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 290.3263 - acc: 0.0000e+00 - val_loss: 348.1354 - val_acc: 0.0000e+00\n",
      "Epoch 491/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 298.0497 - acc: 0.0000e+00 - val_loss: 348.3440 - val_acc: 0.0000e+00\n",
      "Epoch 492/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 325.3493 - acc: 0.0000e+00 - val_loss: 348.4897 - val_acc: 0.0000e+00\n",
      "Epoch 493/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 340.6751 - acc: 0.0000e+00 - val_loss: 348.6813 - val_acc: 0.0000e+00\n",
      "Epoch 494/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 277.9907 - acc: 0.0000e+00 - val_loss: 348.8875 - val_acc: 0.0000e+00\n",
      "Epoch 495/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 329.4707 - acc: 0.0000e+00 - val_loss: 349.0427 - val_acc: 0.0000e+00\n",
      "Epoch 496/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 316.3892 - acc: 0.0476 - val_loss: 349.2192 - val_acc: 0.0000e+00\n",
      "Epoch 497/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 300.5339 - acc: 0.0000e+00 - val_loss: 349.3390 - val_acc: 0.0000e+00\n",
      "Epoch 498/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 301.3462 - acc: 0.0000e+00 - val_loss: 349.5370 - val_acc: 0.0000e+00\n",
      "Epoch 499/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 288.4730 - acc: 0.0000e+00 - val_loss: 349.7224 - val_acc: 0.0000e+00\n",
      "Epoch 500/500\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 326.3519 - acc: 0.0952 - val_loss: 349.9380 - val_acc: 0.0000e+00\n",
      "Train Score: 308.67 MSE (17.57 RMSE)\n",
      "Test Score: 455.57 MSE (21.34 RMSE)\n",
      "['loss', 'acc']\n",
      "valor: 40.000000 ---> Previsão: 31.764736 Diff: 8.235264 Racio: 0.259258\n",
      "valor: 49.000000 ---> Previsão: 31.764261 Diff: 17.235739 Racio: 0.542614\n",
      "valor: 7.000000 ---> Previsão: 31.763794 Diff: 24.763794 Racio: -0.779623\n",
      "valor: 52.000000 ---> Previsão: 31.763750 Diff: 20.236250 Racio: 0.637086\n",
      "valor: 65.000000 ---> Previsão: 31.763704 Diff: 33.236296 Racio: 1.046361\n",
      "valor: 17.000000 ---> Previsão: 31.764391 Diff: 14.764391 Racio: -0.464810\n",
      "valor: 5.000000 ---> Previsão: 31.763699 Diff: 26.763699 Racio: -0.842588\n",
      "valor: 17.000000 ---> Previsão: 31.763699 Diff: 14.763699 Racio: -0.464798\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    " #visualize_GOOGL()\n",
    " LSTM_()\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
