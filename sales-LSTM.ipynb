{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math, time\n",
    "import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# fixar random seed para se puder reproduzir os resultados\n",
    "seed = 9\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_dataset(file_name):\n",
    "    df = pd.read_csv(file_name)\n",
    "    print('Formato do dataset: ',df.shape)\n",
    "    print('Feature Engineering...')\n",
    "    date_split = df['Month'].str.split('-').str\n",
    "    df['Year'], df['Month'] = date_split\n",
    "    m = {'Jan':1, 'Feb':2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6, 'Jul':7, 'Aug':8, 'Sep':9, 'Oct':10, 'Nov':11, 'Dec':12, }\n",
    "    df['Month'] = df['Month'].map(m)\n",
    "    df.drop(df.columns[[3,4,5,6]], axis=1, inplace=True) #vou só ficar com as colunas 0,1,2,6\n",
    "    df.drop(df.tail(2).index,inplace=True) #eliminar as duas últimas linhas com lixo\n",
    "    df.dropna() #just to be sure\n",
    "    df[\"Year\"] = df[\"Year\"].astype(dtype=np.float64) #converter coluna do ano para floats\n",
    "    print('Formato do dataset: ',df.shape)\n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função load_data do lstm.py configurada para aceitar qualquer número de parametros\n",
    "#o último atributo é que fica como label (resultado)\n",
    "#stock é um dataframe do pandas (uma especie de dicionario + matriz)\n",
    "#seq_len é o tamanho da janela a ser utilizada na serie temporal\n",
    "def load_data(df_dados, janela):\n",
    "    #print(df_dados)\n",
    "    qt_atributos = len(df_dados.columns)\n",
    "    tam_sequencia = janela + 1\n",
    "    #converter dataframe para matriz (lista com lista de cada registo) fazendo a divisão já em dados de teste e treino\n",
    "    train_matrix =  df_dados.iloc[:24].as_matrix()\n",
    "    test_matrix = df_dados.iloc[24:].as_matrix()\n",
    "    \n",
    "    #processamento dados de treino de acordo com o tamanho da janela\n",
    "    train = []\n",
    "    for i in range(len(train_matrix) - tam_sequencia): #numero de registos - tamanho da sequencia\n",
    "        train.append(train_matrix[i: i + tam_sequencia])\n",
    "    train = np.array(train) #dá como resultado um np com uma lista de matrizes (janela deslizante ao longo da serie)\n",
    "    #print(train.shape)\n",
    "    \n",
    "    #processamento dados de test de acordo com o tamanho da janela\n",
    "    test = []\n",
    "    for i in range(len(test_matrix) - tam_sequencia):\n",
    "        test.append(test_matrix[i: i + tam_sequencia])\n",
    "    test = np.array(test)\n",
    "    #print(test.shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    x_train = train[:, :-1] #menos um registo pois o ultimo registo é o registo a seguir à janela\n",
    "    y_train = train[:, -1][:,2] #para ir buscar o atributo referente às sales para a lista dos labels\n",
    "    x_test = test[:, :-1]\n",
    "    y_test = test[:, -1][:,2]\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], qt_atributos))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], qt_atributos))\n",
    "   # print(\"TRAIN\",train)\n",
    "   # print(\"TEST\",test)\n",
    "   # print(\"X_TRAIN\",x_train)\n",
    "   # print(\"Y_TRAIN\",y_train)\n",
    "   # print(\"X_TEST\",x_test)\n",
    "   # print(\"Y_TEST\",y_test)\n",
    "    return [x_train,y_train,x_test,y_test]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etapa 2 - Definir a topologia da rede (arquitectura do modelo) e compilar '''\n",
    "def build_model2(janela):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(janela, 4), return_sequences=True))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(LSTM(64, input_shape=(janela, 4), return_sequences=True))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(32, input_shape=(janela, 4), return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(Dense(1, activation=\"linear\", kernel_initializer=\"uniform\"))\n",
    "    model.compile(loss='mse',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(model,fich):\n",
    " from keras.utils import plot_model\n",
    " plot_model(model, to_file=fich, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imprime um grafico com os valores de teste e com as correspondentes tabela de previsões\n",
    "def print_series_prediction(y_test,predic):\n",
    "    diff=[]\n",
    "    racio=[]\n",
    "    for i in range(len(y_test)): #para imprimir tabela de previsoes\n",
    "        racio.append( (y_test[i]/predic[i])-1)\n",
    "        diff.append( abs(y_test[i]- predic[i]))\n",
    "        print('valor: %f ---> Previsão: %f Diff: %f Racio: %f' % (y_test[i],predic[i], diff[i],racio[i]))\n",
    "    plt.plot(y_test,color='blue', label='y_test')\n",
    "    plt.plot(predic,color='red', label='prediction') #este deu uma linha em branco\n",
    "    plt.plot(diff,color='green', label='diff')\n",
    "    plt.plot(racio,color='yellow', label='racio')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization (df):\n",
    "    \n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    scaled_features = min_max_scaler.fit_transform(df)\n",
    "    df = pd.DataFrame(scaled_features,columns=df.columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing (df):\n",
    "    \n",
    "    df['Month'] = df['Month'] / 100\n",
    "    df['Advertising'] = df['Advertising'] / 100\n",
    "    df['Sales'] = df['Sales'] / 100\n",
    "    df['Year'] = df['Year'] / 100\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_():\n",
    "    df = read_csv_dataset(\"advertising-and-sales-data-36-co.csv\")\n",
    "    df = pre_processing(df)\n",
    "    print(\"df\", df.shape)\n",
    "    print(df.head())\n",
    "    janela = 2 #tamanho da Janela deslizante\n",
    "    #X_train, y_train, X_test, y_test = load_data(df[::-1], janela)# o df[::-1] é o df por ordem inversa\n",
    "    X_train, y_train, X_test, y_test = load_data(df, janela)# o ler o def por ordem normal\n",
    "    print(\"X_train\", X_train.shape)\n",
    "    print(\"y_train\", y_train.shape)\n",
    "    print(\"X_test\", X_test.shape)\n",
    "    print(\"y_test\", y_test.shape)\n",
    "    model = build_model2(janela)\n",
    "    model.fit(X_train, y_train, batch_size=4, epochs=200, validation_split=0.1, verbose=1)\n",
    "    #print_model(model,\"lstm_model.png\")\n",
    "    trainScore = model.evaluate(X_train, y_train, verbose=0)\n",
    "    print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore[0], math.sqrt(trainScore[0])))\n",
    "    testScore = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore[0], math.sqrt(testScore[0])))\n",
    "    print(model.metrics_names)\n",
    "    p = model.predict(X_test)\n",
    "    predic = np.squeeze(np.asarray(p)) #para transformar uma matriz de uma coluna e n linhas em um np array de n elementos\n",
    "    print_series_prediction(y_test,predic)\n",
    "    # MSE- (Mean square error), RMSE- (root mean square error) - \n",
    "    # o significado de RMSE depende do range da label. para o mesmo range menor é melhor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato do dataset:  (38, 7)\n",
      "Feature Engineering...\n",
      "Formato do dataset:  (36, 4)\n",
      "   Month  Advertising  Sales  Year\n",
      "0    1.0         12.0   15.0   1.0\n",
      "1    2.0         20.5   16.0   1.0\n",
      "2    3.0         21.0   18.0   1.0\n",
      "3    4.0         15.5   27.0   1.0\n",
      "4    5.0         15.3   21.0   1.0\n",
      "df (36, 4)\n",
      "   Month  Advertising  Sales  Year\n",
      "0   0.01        0.120   0.15  0.01\n",
      "1   0.02        0.205   0.16  0.01\n",
      "2   0.03        0.210   0.18  0.01\n",
      "3   0.04        0.155   0.27  0.01\n",
      "4   0.05        0.153   0.21  0.01\n",
      "X_train (21, 2, 4)\n",
      "y_train (21,)\n",
      "X_test (9, 2, 4)\n",
      "y_test (9,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:10: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18 samples, validate on 3 samples\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 33s 2s/step - loss: 0.1478 - acc: 0.0000e+00 - val_loss: 0.0376 - val_acc: 0.0000e+00\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1428 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1376 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1312 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.1235 - acc: 0.0000e+00 - val_loss: 0.0236 - val_acc: 0.0000e+00\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.1135 - acc: 0.0000e+00 - val_loss: 0.0179 - val_acc: 0.0000e+00\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0989 - acc: 0.0000e+00 - val_loss: 0.0110 - val_acc: 0.0000e+00\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0833 - acc: 0.0000e+00 - val_loss: 0.0048 - val_acc: 0.0000e+00\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0568 - acc: 0.0000e+00 - val_loss: 0.0059 - val_acc: 0.0000e+00\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0406 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0602 - val_acc: 0.0000e+00\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0297 - acc: 0.0000e+00 - val_loss: 0.0600 - val_acc: 0.0000e+00\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0303 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0334 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0000e+00\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0235 - val_acc: 0.0000e+00\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0273 - val_acc: 0.0000e+00\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0354 - acc: 0.0000e+00 - val_loss: 0.0363 - val_acc: 0.0000e+00\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0437 - val_acc: 0.0000e+00\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0380 - val_acc: 0.0000e+00\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0296 - acc: 0.0000e+00 - val_loss: 0.0322 - val_acc: 0.0000e+00\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0273 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0290 - acc: 0.0000e+00 - val_loss: 0.0284 - val_acc: 0.0000e+00\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0274 - acc: 0.0000e+00 - val_loss: 0.0308 - val_acc: 0.0000e+00\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0325 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0300 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0264 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0316 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0000e+00\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0376 - val_acc: 0.0000e+00\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0390 - val_acc: 0.0000e+00\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0381 - val_acc: 0.0000e+00\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0318 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0268 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0291 - acc: 0.0000e+00 - val_loss: 0.0289 - val_acc: 0.0000e+00\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0277 - val_acc: 0.0000e+00\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0315 - acc: 0.0000e+00 - val_loss: 0.0276 - val_acc: 0.0000e+00\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0366 - val_acc: 0.0000e+00\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0428 - val_acc: 0.0000e+00\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0420 - val_acc: 0.0000e+00\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0222 - acc: 0.0000e+00 - val_loss: 0.0420 - val_acc: 0.0000e+00\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0431 - val_acc: 0.0000e+00\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0389 - val_acc: 0.0000e+00\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0262 - acc: 0.0000e+0 - 0s 7ms/step - loss: 0.0250 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0357 - val_acc: 0.0000e+00\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0321 - acc: 0.0000e+00 - val_loss: 0.0376 - val_acc: 0.0000e+00\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0275 - acc: 0.0000e+00 - val_loss: 0.0397 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0327 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0298 - acc: 0.0000e+00 - val_loss: 0.0304 - val_acc: 0.0000e+00\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0284 - val_acc: 0.0000e+00\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0282 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0388 - val_acc: 0.0000e+00\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0340 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0302 - val_acc: 0.0000e+00\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0000e+00\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0286 - acc: 0.0000e+00 - val_loss: 0.0283 - val_acc: 0.0000e+00\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0317 - val_acc: 0.0000e+00\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0326 - val_acc: 0.0000e+00\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0333 - acc: 0.0000e+00 - val_loss: 0.0266 - val_acc: 0.0000e+00\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0320 - acc: 0.0000e+00 - val_loss: 0.0256 - val_acc: 0.0000e+00\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0289 - acc: 0.0000e+00 - val_loss: 0.0264 - val_acc: 0.0000e+00\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0244 - val_acc: 0.0000e+00\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0244 - val_acc: 0.0000e+00\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0262 - acc: 0.0000e+00 - val_loss: 0.0274 - val_acc: 0.0000e+00\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0311 - val_acc: 0.0000e+00\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0330 - val_acc: 0.0000e+00\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0361 - val_acc: 0.0000e+00\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0240 - acc: 0.0000e+00 - val_loss: 0.0379 - val_acc: 0.0000e+00\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0215 - acc: 0.0000e+00 - val_loss: 0.0373 - val_acc: 0.0000e+00\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0285 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0257 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0306 - val_acc: 0.0000e+00\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0314 - val_acc: 0.0000e+00\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0245 - acc: 0.0000e+00 - val_loss: 0.0301 - val_acc: 0.0000e+00\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0328 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0308 - val_acc: 0.0000e+00\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0239 - acc: 0.0000e+00 - val_loss: 0.0331 - val_acc: 0.0000e+00\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0213 - acc: 0.0000e+00 - val_loss: 0.0321 - val_acc: 0.0000e+00\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.0272 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0324 - val_acc: 0.0000e+00\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0306 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0308 - acc: 0.0000e+00 - val_loss: 0.0350 - val_acc: 0.0000e+00\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0250 - acc: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.0000e+00\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0246 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0240 - acc: 0.0000e+00 - val_loss: 0.0368 - val_acc: 0.0000e+00\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0287 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0196 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0313 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0279 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0231 - acc: 0.0000e+00 - val_loss: 0.0366 - val_acc: 0.0000e+00\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0426 - val_acc: 0.0000e+00\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0241 - acc: 0.0000e+00 - val_loss: 0.0410 - val_acc: 0.0000e+00\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0379 - val_acc: 0.0000e+00\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0404 - val_acc: 0.0000e+00\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0330 - acc: 0.0000e+00 - val_loss: 0.0392 - val_acc: 0.0000e+00\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0240 - acc: 0.0000e+00 - val_loss: 0.0353 - val_acc: 0.0000e+00\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0294 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0271 - acc: 0.0000e+00 - val_loss: 0.0296 - val_acc: 0.0000e+00\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0220 - acc: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.0000e+00\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0243 - acc: 0.0000e+00 - val_loss: 0.0338 - val_acc: 0.0000e+00\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0284 - acc: 0.0000e+00 - val_loss: 0.0370 - val_acc: 0.0000e+00\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0254 - acc: 0.0000e+00 - val_loss: 0.0391 - val_acc: 0.0000e+00\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0207 - acc: 0.0000e+00 - val_loss: 0.0351 - val_acc: 0.0000e+00\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0352 - val_acc: 0.0000e+00\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0255 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0270 - acc: 0.0000e+00 - val_loss: 0.0320 - val_acc: 0.0000e+00\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0270 - val_acc: 0.0000e+00\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0240 - acc: 0.0000e+00 - val_loss: 0.0280 - val_acc: 0.0000e+00\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0293 - acc: 0.0000e+00 - val_loss: 0.0347 - val_acc: 0.0000e+00\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0365 - val_acc: 0.0000e+00\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0238 - acc: 0.0000e+00 - val_loss: 0.0312 - val_acc: 0.0000e+00\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0310 - val_acc: 0.0000e+00\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0281 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0211 - acc: 0.0000e+00 - val_loss: 0.0358 - val_acc: 0.0000e+00\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0290 - acc: 0.0000e+00 - val_loss: 0.0387 - val_acc: 0.0000e+00\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0253 - acc: 0.0000e+00 - val_loss: 0.0359 - val_acc: 0.0000e+00\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0340 - val_acc: 0.0000e+00\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0239 - acc: 0.0000e+0 - 0s 8ms/step - loss: 0.0237 - acc: 0.0000e+00 - val_loss: 0.0305 - val_acc: 0.0000e+00\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0260 - acc: 0.0000e+00 - val_loss: 0.0298 - val_acc: 0.0000e+00\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0222 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0000e+00\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.0208 - acc: 0.0000e+0 - 0s 9ms/step - loss: 0.0263 - acc: 0.0000e+00 - val_loss: 0.0354 - val_acc: 0.0000e+00\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0208 - acc: 0.0000e+00 - val_loss: 0.0309 - val_acc: 0.0000e+00\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0307 - val_acc: 0.0000e+00\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0258 - val_acc: 0.0000e+00\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0288 - acc: 0.0000e+00 - val_loss: 0.0297 - val_acc: 0.0000e+00\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0277 - acc: 0.0000e+00 - val_loss: 0.0274 - val_acc: 0.0000e+00\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0244 - acc: 0.0000e+00 - val_loss: 0.0313 - val_acc: 0.0000e+00\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.0228 - acc: 0.0000e+00 - val_loss: 0.0384 - val_acc: 0.0000e+00\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.0247 - acc: 0.0000e+00 - val_loss: 0.0406 - val_acc: 0.0000e+00\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0246 - acc: 0.0000e+00 - val_loss: 0.0442 - val_acc: 0.0000e+00\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0256 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0216 - acc: 0.0000e+00 - val_loss: 0.0335 - val_acc: 0.0000e+00\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0266 - acc: 0.0000e+00 - val_loss: 0.0372 - val_acc: 0.0000e+00\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0246 - acc: 0.0000e+00 - val_loss: 0.0336 - val_acc: 0.0000e+00\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0251 - acc: 0.0000e+00 - val_loss: 0.0308 - val_acc: 0.0000e+00\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0228 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.0000e+00 - val_loss: 0.0437 - val_acc: 0.0000e+00\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0259 - acc: 0.0000e+00 - val_loss: 0.0415 - val_acc: 0.0000e+00\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0221 - acc: 0.0000e+00 - val_loss: 0.0348 - val_acc: 0.0000e+00\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0252 - acc: 0.0000e+00 - val_loss: 0.0275 - val_acc: 0.0000e+00\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0235 - acc: 0.0000e+00 - val_loss: 0.0281 - val_acc: 0.0000e+00\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0337 - val_acc: 0.0000e+00\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0432 - val_acc: 0.0000e+00\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0292 - acc: 0.0000e+00 - val_loss: 0.0439 - val_acc: 0.0000e+00\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0383 - val_acc: 0.0000e+00\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0239 - acc: 0.0000e+00 - val_loss: 0.0391 - val_acc: 0.0000e+00\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0219 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0233 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0248 - acc: 0.0000e+00 - val_loss: 0.0303 - val_acc: 0.0000e+00\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0258 - acc: 0.0000e+00 - val_loss: 0.0328 - val_acc: 0.0000e+00\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0223 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0197 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0219 - acc: 0.0000e+00 - val_loss: 0.0374 - val_acc: 0.0000e+00\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0236 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0291 - val_acc: 0.0000e+00\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0329 - val_acc: 0.0000e+00\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0195 - acc: 0.0000e+00 - val_loss: 0.0433 - val_acc: 0.0000e+00\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.0225 - acc: 0.0000e+00 - val_loss: 0.0430 - val_acc: 0.0000e+00\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0210 - acc: 0.0000e+00 - val_loss: 0.0346 - val_acc: 0.0000e+00\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0229 - acc: 0.0000e+00 - val_loss: 0.0345 - val_acc: 0.0000e+00\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0203 - acc: 0.0000e+00 - val_loss: 0.0333 - val_acc: 0.0000e+00\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0222 - acc: 0.0000e+00 - val_loss: 0.0343 - val_acc: 0.0000e+00\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0181 - acc: 0.0000e+00 - val_loss: 0.0360 - val_acc: 0.0000e+00\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0212 - acc: 0.0000e+00 - val_loss: 0.0323 - val_acc: 0.0000e+00\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0250 - acc: 0.0000e+00 - val_loss: 0.0341 - val_acc: 0.0000e+00\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0308 - val_acc: 0.0000e+00\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0261 - acc: 0.0000e+00 - val_loss: 0.0342 - val_acc: 0.0000e+00\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0215 - acc: 0.0000e+00 - val_loss: 0.0332 - val_acc: 0.0000e+00\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0191 - acc: 0.0000e+00 - val_loss: 0.0356 - val_acc: 0.0000e+00\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0230 - acc: 0.0000e+00 - val_loss: 0.0349 - val_acc: 0.0000e+00\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0244 - acc: 0.0000e+00 - val_loss: 0.0325 - val_acc: 0.0000e+00\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0197 - acc: 0.0000e+00 - val_loss: 0.0290 - val_acc: 0.0000e+00\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0231 - acc: 0.0000e+00 - val_loss: 0.0248 - val_acc: 0.0000e+00\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0278 - acc: 0.0000e+00 - val_loss: 0.0242 - val_acc: 0.0000e+00\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0249 - acc: 0.0000e+00 - val_loss: 0.0318 - val_acc: 0.0000e+00\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.0209 - acc: 0.0000e+00 - val_loss: 0.0339 - val_acc: 0.0000e+00\n",
      "Train Score: 0.02 MSE (0.15 RMSE)\n",
      "Test Score: 0.05 MSE (0.23 RMSE)\n",
      "['loss', 'acc']\n",
      "valor: 0.360000 ---> Previsão: 0.353567 Diff: 0.006433 Racio: 0.018194\n",
      "valor: 0.400000 ---> Previsão: 0.384032 Diff: 0.015968 Racio: 0.041580\n",
      "valor: 0.490000 ---> Previsão: 0.433096 Diff: 0.056904 Racio: 0.131389\n",
      "valor: 0.070000 ---> Previsão: 0.440735 Diff: 0.370735 Racio: -0.841174\n",
      "valor: 0.520000 ---> Previsão: 0.416115 Diff: 0.103885 Racio: 0.249655\n",
      "valor: 0.650000 ---> Previsão: 0.335325 Diff: 0.314675 Racio: 0.938421\n",
      "valor: 0.170000 ---> Previsão: 0.436953 Diff: 0.266953 Racio: -0.610942\n",
      "valor: 0.050000 ---> Previsão: 0.419940 Diff: 0.369940 Racio: -0.880935\n",
      "valor: 0.170000 ---> Previsão: 0.288035 Diff: 0.118035 Racio: -0.409794\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    " #visualize_GOOGL()\n",
    " LSTM_()\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
